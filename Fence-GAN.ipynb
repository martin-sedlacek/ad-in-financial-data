{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import data_utils\n",
    "from models.FenceGAN import Generator, Discriminator\n",
    "from training.FenceGAN_train import FenceGanTrainingPipeline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "batch_size = 256\n",
    "random_seed = 0\n",
    "num_features = 6\n",
    "seq_length = 1\n",
    "seq_stride = 10\n",
    "gen_seq_len = seq_length\n",
    "# Model\n",
    "latent_dim = 30\n",
    "# Training\n",
    "gen_lr = 1e-4\n",
    "gen_wd = 1e-3\n",
    "dis_lr = 8e-6\n",
    "dis_wd = 1e-3\n",
    "dis_momentum = 0.9\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"kdd99_small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"kdd99_small\":\n",
    "    train_dl, test_dl = data_utils.kdd99(seq_length, seq_stride, num_features, gen_seq_len, batch_size)\n",
    "elif dataset == \"kdd99_large\":\n",
    "    train_dl_normal = data_utils.large_kdd99('data/kdd99/X_train_normal.npy', seq_length, seq_stride, num_features, gen_seq_len,batch_size)\n",
    "    train_dl_anomaly = data_utils.large_kdd99('data/kdd99/X_train_anomaly.npy', seq_length, seq_stride, num_features, gen_seq_len,batch_size)\n",
    "    test_dl_normal = data_utils.large_kdd99('data/kdd99/X_test_normal.npy', seq_length, seq_stride, num_features, gen_seq_len,batch_size)\n",
    "    test_dl_anomaly = data_utils.large_kdd99('data/kdd99/X_test_anomaly.npy', seq_length, seq_stride, num_features, gen_seq_len,batch_size)\n",
    "elif dataset == \"apple\":\n",
    "    file_path = './data/Stocks/aapl.us.txt'\n",
    "    tscv_dl_list = data_utils.load_stock_as_crossvalidated_timeseries(file_path, seq_length, seq_stride, gen_seq_len, batch_size, normalise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use xavier initialization for weights\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (linear1): Linear(in_features=30, out_features=64, bias=True)\n",
       "  (linear2): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (linear3): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator(input_dim=latent_dim,output_dim=num_features).to(device=DEVICE)\n",
    "generator.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (linear1): Linear(in_features=6, out_features=256, bias=True)\n",
       "  (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (linear3): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (linear4): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = Discriminator(input_dim=num_features).to(device=DEVICE)\n",
    "discriminator.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generator_optim = torch.optim.Adam(generator.parameters(), lr=gen_lr, weight_decay=gen_wd)\n",
    "discriminator_optim = torch.optim.SGD(discriminator.parameters(), lr=dis_lr, weight_decay=dis_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispersion_loss(G_out, y_pred, y_true):\n",
    "    dispersion_weight = 30\n",
    "    loss_b = nn.BCELoss()(y_pred, y_true)\n",
    "    center = G_out.mean(dim=0, keepdims=True)\n",
    "    distance_xy = torch.square(torch.subtract(G_out, center))\n",
    "    distance = distance_xy.sum(dim=1)\n",
    "    avg_distance = torch.sqrt(distance).mean()\n",
    "    loss_d = torch.reciprocal(avg_distance)\n",
    "    loss = loss_b + dispersion_weight*loss_d\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_loss(real_pred, real_true, fake_pred, fake_true):\n",
    "    gen_weight = 0.5\n",
    "    loss_real = nn.BCELoss()(real_pred, real_true)\n",
    "    loss_gen = nn.BCELoss()(fake_pred, fake_true)\n",
    "    loss = loss_real + gen_weight * loss_gen\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = FenceGanTrainingPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training:\n",
      "G_loss: 19.338057899475096, D_loss: 1.1276006395166571\n",
      "Epoch 1 training:\n",
      "G_loss: 10.747882652282716, D_loss: 1.1266415829008276\n",
      "Epoch 2 training:\n",
      "G_loss: 7.354594523256475, D_loss: 1.1357076281850988\n",
      "Epoch 3 training:\n",
      "G_loss: 5.50076459754597, D_loss: 1.156045286763798\n",
      "Epoch 4 training:\n",
      "G_loss: 4.354316354881633, D_loss: 1.1847474645484577\n",
      "Epoch 5 training:\n",
      "G_loss: 3.5926332809708335, D_loss: 1.2097719685597854\n",
      "Epoch 6 training:\n",
      "G_loss: 3.047925609892065, D_loss: 1.2274696967818521\n",
      "Epoch 7 training:\n",
      "G_loss: 2.6655534083192998, D_loss: 1.235485921122811\n",
      "Epoch 8 training:\n",
      "G_loss: 2.4161304235458374, D_loss: 1.2257977864959024\n",
      "Epoch 9 training:\n",
      "G_loss: 2.262792724912817, D_loss: 1.2103874385356903\n",
      "Epoch 10 training:\n",
      "G_loss: 2.1753327505155045, D_loss: 1.2017200811342759\n",
      "Epoch 11 training:\n",
      "G_loss: 2.1139880245382137, D_loss: 1.2020989954471588\n",
      "Epoch 12 training:\n",
      "G_loss: 2.031764817237854, D_loss: 1.224377325448123\n",
      "Epoch 13 training:\n",
      "G_loss: 1.9367716805501418, D_loss: 1.2723082049326464\n",
      "Epoch 14 training:\n",
      "G_loss: 1.8460473483259028, D_loss: 1.3236946230584925\n",
      "Epoch 15 training:\n",
      "G_loss: 1.8378047813068736, D_loss: 1.3416412516073748\n",
      "Epoch 16 training:\n",
      "G_loss: 1.9241351040926846, D_loss: 1.3078839182853699\n",
      "Epoch 17 training:\n",
      "G_loss: 2.159212104298852, D_loss: 1.226159231229262\n",
      "Epoch 18 training:\n",
      "G_loss: 2.3996745412999934, D_loss: 1.1529093487696214\n",
      "Epoch 19 training:\n",
      "G_loss: 2.53860552852804, D_loss: 1.1123047124255787\n",
      "Epoch 20 training:\n",
      "G_loss: 2.5248036644675516, D_loss: 1.0938974889841946\n",
      "Epoch 21 training:\n",
      "G_loss: 2.5161151257428256, D_loss: 1.082898235321045\n",
      "Epoch 22 training:\n",
      "G_loss: 2.478157392415133, D_loss: 1.0809987366199494\n",
      "Epoch 23 training:\n",
      "G_loss: 2.398099633780393, D_loss: 1.0958352717486295\n",
      "Epoch 24 training:\n",
      "G_loss: 2.33397622758692, D_loss: 1.1038181993094358\n",
      "Epoch 25 training:\n",
      "G_loss: 2.342817130955783, D_loss: 1.0912123121998527\n",
      "Epoch 26 training:\n",
      "G_loss: 2.389869194680994, D_loss: 1.0677612456408414\n",
      "Epoch 27 training:\n",
      "G_loss: 2.4322991880503566, D_loss: 1.0506149042736401\n",
      "Epoch 28 training:\n",
      "G_loss: 2.4568405281413686, D_loss: 1.0410951760682192\n",
      "Epoch 29 training:\n",
      "G_loss: 2.4284375895153394, D_loss: 1.042456425861879\n",
      "Epoch 30 training:\n",
      "G_loss: 2.399365204030817, D_loss: 1.0386012743819844\n",
      "Epoch 31 training:\n",
      "G_loss: 2.418942329016599, D_loss: 1.0327476533976467\n",
      "Epoch 32 training:\n",
      "G_loss: 2.4377620046788997, D_loss: 1.025368155945431\n",
      "Epoch 33 training:\n",
      "G_loss: 2.460548530925404, D_loss: 1.0198754020712593\n",
      "Epoch 34 training:\n",
      "G_loss: 2.4752896839922123, D_loss: 1.0161310426213526\n",
      "Epoch 35 training:\n",
      "G_loss: 2.480585471066562, D_loss: 1.0128945223309778\n",
      "Epoch 36 training:\n",
      "G_loss: 2.4899920897050336, D_loss: 1.0121286392211915\n",
      "Epoch 37 training:\n",
      "G_loss: 2.490189935944297, D_loss: 1.009463680061427\n",
      "Epoch 38 training:\n",
      "G_loss: 2.4978680090470746, D_loss: 1.0102860355919057\n",
      "Epoch 39 training:\n",
      "G_loss: 2.5138705827973107, D_loss: 1.0098385098305616\n",
      "Epoch 40 training:\n",
      "G_loss: 2.5033023259856484, D_loss: 1.011126637187871\n",
      "Epoch 41 training:\n",
      "G_loss: 2.495766486904838, D_loss: 1.0115364088253542\n",
      "Epoch 42 training:\n",
      "G_loss: 2.5144854946569963, D_loss: 1.0125324149023402\n",
      "Epoch 43 training:\n",
      "G_loss: 2.525193511356007, D_loss: 1.0128093337470836\n",
      "Epoch 44 training:\n",
      "G_loss: 2.515599145672538, D_loss: 1.0122382933443244\n",
      "Epoch 45 training:\n",
      "G_loss: 2.5220765428109604, D_loss: 1.0119517315517772\n",
      "Epoch 46 training:\n",
      "G_loss: 2.534069221669977, D_loss: 1.0112605401060797\n",
      "Epoch 47 training:\n",
      "G_loss: 2.5213809024203906, D_loss: 1.0108243877237493\n",
      "Epoch 48 training:\n",
      "G_loss: 2.5285547332330185, D_loss: 1.0069909418171101\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkdd99_small\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_kdd99_small\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisc_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdispersion_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dataset \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkdd99_large\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      4\u001b[0m     pipeline\u001b[38;5;241m.\u001b[39mtrain_kdd99_large(seq_length, latent_dim,  train_dl_normal, train_dl_anomaly, test_dl_anomaly, test_dl_normal, discriminator, generator, discriminator_optim, generator_optim, disc_loss, dispersion_loss, random_seed, num_epochs, DEVICE)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\ml-for-financial-data\\training\\FenceGAN_train.py:97\u001b[0m, in \u001b[0;36mFenceGanTrainingPipeline.train_kdd99_small\u001b[1;34m(self, seq_length, latent_dim, train_dl, test_dl, D, G, D_optim, G_optim, D_loss, G_loss, random_seed, num_epochs, DEVICE)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_seed(random_seed)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(D, test_dl, \u001b[38;5;241m1\u001b[39m, DEVICE)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\ml-for-financial-data\\training\\FenceGAN_train.py:34\u001b[0m, in \u001b[0;36mFenceGanTrainingPipeline.train_epoch\u001b[1;34m(self, D, G, D_loss, G_loss, real_dl, G_optimizer, D_optimizer, seq_length, latent_dim, DEVICE, normal_label, anomaly_label, epoch)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Samples\u001b[39;00m\n\u001b[0;32m     33\u001b[0m real_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m---> 34\u001b[0m latent_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_Z\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     35\u001b[0m fake_samples \u001b[38;5;241m=\u001b[39m G(latent_samples)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Labels\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\ml-for-financial-data\\training\\FenceGAN_train.py:14\u001b[0m, in \u001b[0;36mFenceGanTrainingPipeline.sample_Z\u001b[1;34m(self, batch_size, seq_length, latent_dim)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_Z\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_size, seq_length, latent_dim):\n\u001b[1;32m---> 14\u001b[0m     sample \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTensor(sample)\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if dataset == \"kdd99_small\":\n",
    "    pipeline.train_kdd99_small(seq_length, latent_dim,  train_dl, test_dl, discriminator, generator, discriminator_optim, generator_optim, disc_loss, dispersion_loss, random_seed, num_epochs, DEVICE)\n",
    "elif dataset == \"kdd99_large\":\n",
    "    pipeline.train_kdd99_large(seq_length, latent_dim,  train_dl_normal, train_dl_anomaly, test_dl_anomaly, test_dl_normal, discriminator, generator, discriminator_optim, generator_optim, disc_loss, dispersion_loss, random_seed, num_epochs, DEVICE)\n",
    "else:\n",
    "    pipeline.train(seq_length, latent_dim, tscv_dl_list, discriminator, generator, discriminator_optim, generator_optim, disc_loss, dispersion_loss, random_seed, num_epochs, DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
