{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d637f29d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import data_utils\n",
    "from training.MADGAN_train import MadGanTrainingPipeline\n",
    "from models.MADGAN import Generator, Discriminator, AnomalyDetector\n",
    "from utils import evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122afece",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24e5c82d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab1fbed1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_type = \"MAD-GAN\"\n",
    "num_generated_features = 6\n",
    "seq_length = 30\n",
    "seq_stride = 10\n",
    "\n",
    "random_seed = 0\n",
    "num_epochs = 100\n",
    "batch_size = 256\n",
    "lr = 0.001\n",
    "latent_dim = 15\n",
    "hidden_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db595ed4",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d5a32eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load kdd99_train from .npy\n",
      "load kdd99_test from .npy\n"
     ]
    }
   ],
   "source": [
    "train_dl, test_dl = data_utils.load_kdd99(seq_length, seq_stride, num_generated_features,batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be19266",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b8e0254",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = MadGanTrainingPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1791db61",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (lstm): LSTM(15, 100, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (linear): Linear(in_features=100, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator(\n",
    "    latent_space_dim=latent_dim,\n",
    "    hidden_units=hidden_dim,\n",
    "    output_dim=num_generated_features)\n",
    "generator.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5d61fc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (lstm): LSTM(6, 100, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = Discriminator(input_dim=num_generated_features,\n",
    "    hidden_units=hidden_dim,\n",
    "    add_batch_mean=False)\n",
    "discriminator.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79400ae4",
   "metadata": {},
   "source": [
    "# Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4184199c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def loss_function(inputs, targets):\n",
    "    return nn.BCELoss()(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13566602",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "discriminator_optim = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "generator_optim = torch.optim.Adam(generator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e978b34",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "615f760e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0training:\n",
      "G_loss: 1.7593513584949754, D_loss_real: 0.7358834815465591, D_loss_fake: 0.6745875462889671\n",
      "Evaluation metrics: {'D_loss': 3.2228572689807478, 'G_acc': 0.7926544252435623, 'D_acc': 0.7041554832010689}\n",
      "Epoch 1training:\n",
      "G_loss: 1.166362568329681, D_loss_real: 0.658841934190555, D_loss_fake: 0.6912643522024154\n",
      "Evaluation metrics: {'D_loss': 2.166107392681695, 'G_acc': 0.7824344720131684, 'D_acc': 0.42945125023472497}\n",
      "Epoch 2training:\n",
      "G_loss: 1.8515564753250642, D_loss_real: 0.5888545121658932, D_loss_fake: 0.5103977670723742\n",
      "Evaluation metrics: {'D_loss': 2.8735473304214874, 'G_acc': 0.6969164020811338, 'D_acc': 0.4478878229856491}\n",
      "Epoch 3training:\n",
      "G_loss: 1.3480521487918766, D_loss_real: 0.6355280322107402, D_loss_fake: 0.5964607914740389\n",
      "Evaluation metrics: {'D_loss': 1.4254059559940675, 'G_acc': 0.2972450924197627, 'D_acc': 1.3267245119717455}\n",
      "Epoch 4training:\n",
      "G_loss: 1.851536323265596, D_loss_real: 0.5340758550573479, D_loss_fake: 0.43534032485701823\n",
      "Evaluation metrics: {'D_loss': 3.792251651151193, 'G_acc': 0.7895681770721094, 'D_acc': 0.26386460773839854}\n",
      "Epoch 5training:\n",
      "G_loss: 1.9572334536774592, D_loss_real: 0.528399283201857, D_loss_fake: 0.486177051406015\n",
      "Evaluation metrics: {'D_loss': 1.6546662601164586, 'G_acc': 0.30301343282887355, 'D_acc': 1.1426924800625737}\n",
      "Epoch 6training:\n",
      "G_loss: 1.2906517618081785, D_loss_real: 0.5513115353882313, D_loss_fake: 0.5208287211304361\n",
      "Evaluation metrics: {'D_loss': 4.928647665162161, 'G_acc': 0.7323473802347875, 'D_acc': 0.2907727190095526}\n",
      "Epoch 7training:\n",
      "G_loss: 1.4022746619853106, D_loss_real: 0.5755647635256702, D_loss_fake: 0.5300965805622664\n",
      "Evaluation metrics: {'D_loss': 1.8375410551851896, 'G_acc': 0.7630773332413923, 'D_acc': 0.4616740147530106}\n",
      "Epoch 8training:\n",
      "G_loss: 1.6229317730123347, D_loss_real: 0.5460861825807528, D_loss_fake: 0.48319909870624544\n",
      "Evaluation metrics: {'D_loss': 2.216597376709775, 'G_acc': 0.5498867099766904, 'D_acc': 1.0088051994538678}\n",
      "Epoch 9training:\n",
      "G_loss: 2.209693302891471, D_loss_real: 0.4494818732481111, D_loss_fake: 0.4005943193693053\n",
      "Evaluation metrics: {'D_loss': 4.477445748185865, 'G_acc': 0.7182620496638699, 'D_acc': 0.4133889606425182}\n",
      "Epoch 10training:\n",
      "G_loss: 1.7512653136795218, D_loss_real: 0.5019371374086901, D_loss_fake: 0.4769609852947972\n",
      "Evaluation metrics: {'D_loss': 3.4065206223818922, 'G_acc': 0.7517454250102834, 'D_acc': 0.6752883337939959}\n",
      "Epoch 11training:\n",
      "G_loss: 1.590896812352267, D_loss_real: 0.5153951998461377, D_loss_fake: 0.4719194249673323\n",
      "Evaluation metrics: {'D_loss': 2.033858777327859, 'G_acc': 0.5053294432286771, 'D_acc': 0.988367282047173}\n",
      "Epoch 12training:\n",
      "G_loss: 1.4615830196575685, D_loss_real: 0.4936686742712151, D_loss_fake: 0.4964277575639161\n",
      "Evaluation metrics: {'D_loss': 2.5883725097142354, 'G_acc': 0.7956218093976263, 'D_acc': 0.5601888187808693}\n",
      "Epoch 13training:\n",
      "G_loss: 1.9380161424929445, D_loss_real: 0.5235829324715516, D_loss_fake: 0.44586893772198394\n",
      "Evaluation metrics: {'D_loss': 1.581998115994152, 'G_acc': 0.4341613772310741, 'D_acc': 1.164227222840403}\n",
      "Epoch 14training:\n",
      "G_loss: 1.6257784737782044, D_loss_real: 0.4907760919833725, D_loss_fake: 0.4764164112508297\n",
      "Evaluation metrics: {'D_loss': 2.3758876725182017, 'G_acc': 0.7712774703404601, 'D_acc': 0.7155447423535307}\n",
      "Epoch 15training:\n",
      "G_loss: 1.1277957900003954, D_loss_real: 0.5867674837735566, D_loss_fake: 0.552003899352117\n",
      "Evaluation metrics: {'D_loss': 2.147126940865591, 'G_acc': 0.7476564753086455, 'D_acc': 0.8963178927416628}\n",
      "Epoch 16training:\n",
      "G_loss: 1.5218577364628965, D_loss_real: 0.5416709495708346, D_loss_fake: 0.48262771916660396\n",
      "Evaluation metrics: {'D_loss': 2.9549117409503523, 'G_acc': 0.7594989535490466, 'D_acc': 0.9988319256338122}\n",
      "Epoch 17training:\n",
      "G_loss: 2.1473003121939573, D_loss_real: 0.3686032941480252, D_loss_fake: 0.2148875024847009\n",
      "Evaluation metrics: {'D_loss': 4.861133849682585, 'G_acc': 0.7958859877004602, 'D_acc': 0.5014990971911062}\n",
      "Epoch 18training:\n",
      "G_loss: 2.491624974120747, D_loss_real: 0.3350813556504859, D_loss_fake: 0.20104912807318298\n",
      "Evaluation metrics: {'D_loss': 6.173046554308481, 'G_acc': 0.7683893626102203, 'D_acc': 0.45693169235025044}\n",
      "Epoch 19training:\n",
      "G_loss: 2.326773061535575, D_loss_real: 0.397299452570521, D_loss_fake: 0.29005753814496776\n",
      "Evaluation metrics: {'D_loss': 3.01121283936377, 'G_acc': 0.8029576998176547, 'D_acc': 0.9125500816099076}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\ml-for-financial-data\\training\\MADGAN_train.py:130\u001b[0m, in \u001b[0;36mMadGanTrainingPipeline.train\u001b[1;34m(self, seq_length, latent_dim, train_dl, test_dl, D, G, D_optim, G_optim, loss_fn, random_seed, num_epochs, DEVICE, model_dir)\u001b[0m\n\u001b[0;32m    127\u001b[0m model_dir\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mnormal_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manomaly_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(G, D, loss_fn, test_dl, seq_length, latent_dim, DEVICE, normal_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, anomaly_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    134\u001b[0m     G\u001b[38;5;241m.\u001b[39msave(model_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\ml-for-financial-data\\training\\MADGAN_train.py:112\u001b[0m, in \u001b[0;36mMadGanTrainingPipeline.train_epoch\u001b[1;34m(self, G, D, loss_fn, real_dl, G_optimizer, D_optimizer, seq_length, latent_dim, DEVICE, normal_label, anomaly_label, epoch, log_every)\u001b[0m\n\u001b[0;32m    109\u001b[0m G_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Save metrics\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m metric_accum[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator_loss\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mg_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m metric_accum[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscriminator_loss_real\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m d_loss_real\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    114\u001b[0m metric_accum[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscriminator_loss_fake\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m d_loss_fake\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline.train(seq_length, latent_dim, train_dl, test_dl, discriminator, generator, discriminator_optim, generator_optim, \n",
    "                loss_function, random_seed, num_epochs, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d4623",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dda164e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71bf376f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def scoring_function(model, data):\n",
    "    x = torch.tensor(data, dtype=torch.float32).unsqueeze(dim=0)\n",
    "    out = model.predict(x).squeeze()\n",
    "    return out.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b58d8ddb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def torch_scoring_function(model, data):\n",
    "    return model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41547c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_emmv_scores(trained_model, x, scoring_func=None, n_generated=10000, alpha_min=0.9, alpha_max=0.999,\n",
    "                      t_max=0.9):\n",
    "    # Get limits and volume support.\n",
    "    lim_inf = torch.min(x.view(-1, 6), dim=0)[0]\n",
    "    lim_sup = torch.max(x.view(-1, 6), dim=0)[0]\n",
    "    offset = 1e-60  # to prevent division by 0\n",
    "\n",
    "    # Volume support\n",
    "    volume_support = torch.prod(lim_sup - lim_inf).item() + offset\n",
    "\n",
    "    # Determine EM and MV parameters\n",
    "    t = np.arange(0, 100 / volume_support, 0.01 / volume_support)\n",
    "    axis_alpha = np.arange(alpha_min, alpha_max, 0.0001)\n",
    "\n",
    "    unif = torch.rand(n_generated, x.size(1), x.size(2))\n",
    "    m = lim_sup - lim_inf\n",
    "    unif = unif * m\n",
    "    unif = unif + lim_inf\n",
    "\n",
    "    # Get anomaly scores\n",
    "    anomaly_score = scoring_func(trained_model, x).view(-1, 1).detach().numpy()\n",
    "    s_unif = scoring_func(trained_model, unif).view(-1, 1).detach().numpy()\n",
    "    print(anomaly_score.shape,s_unif.shape)\n",
    "    \n",
    "    # Get EM and MV scores\n",
    "    AUC_em, em, amax = evaluation.excess_mass(t, t_max, volume_support, s_unif, anomaly_score, n_generated)\n",
    "    AUC_mv, mv = evaluation.mass_volume(axis_alpha, volume_support, s_unif, anomaly_score, n_generated)\n",
    "\n",
    "    # Return a dataframe containing EMMV information\n",
    "    scores = {\n",
    "        'em': np.mean(em),\n",
    "        'mv': np.mean(mv),\n",
    "    }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cb4d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = AnomalyDetector(discriminator=discriminator, generator=generator, latent_space_dim=latent_dim, anomaly_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3d8626f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n",
      "(7680, 1) (300000, 1)\n",
      "{'em': 0.0001, 'mv': 14253.036804199219}\n",
      "abc\n",
      "(7680, 1) (300000, 1)\n",
      "{'em': 0.0001, 'mv': 11815.361022949219}\n",
      "abc\n",
      "(7680, 1) (300000, 1)\n",
      "{'em': 0.0001, 'mv': 8953.750305175781}\n",
      "abc\n",
      "(7680, 1) (300000, 1)\n",
      "{'em': 0.0011373735166666664, 'mv': 6839.769287109375}\n",
      "abc\n",
      "(7680, 1) (300000, 1)\n",
      "{'em': 0.0002725416333333333, 'mv': 7061.930943310547}\n",
      "abc\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m     recall \u001b[38;5;241m=\u001b[39m true_positives \u001b[38;5;241m/\u001b[39m (true_positives\u001b[38;5;241m+\u001b[39mfalse_negatives)\n\u001b[0;32m     26\u001b[0m     total_recall \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m recall\n\u001b[1;32m---> 28\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_emmv_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mad\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch_scoring_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(scores)\n\u001b[0;32m     31\u001b[0m total_em \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mem\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36mtorch_emmv_scores\u001b[1;34m(trained_model, x, scoring_func, n_generated, alpha_min, alpha_max, t_max)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Get anomaly scores\u001b[39;00m\n\u001b[0;32m     22\u001b[0m anomaly_score \u001b[38;5;241m=\u001b[39m scoring_func(trained_model, x)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 23\u001b[0m s_unif \u001b[38;5;241m=\u001b[39m \u001b[43mscoring_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munif\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(anomaly_score\u001b[38;5;241m.\u001b[39mshape,s_unif\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Get EM and MV scores\u001b[39;00m\n",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36mtorch_scoring_function\u001b[1;34m(model, data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtorch_scoring_function\u001b[39m(model, data):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\ml-for-financial-data\\models\\MADGAN.py:127\u001b[0m, in \u001b[0;36mAnomalyDetector.predict\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold)\u001b[38;5;241m.\u001b[39mint()\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\ml-for-financial-data\\models\\MADGAN.py:132\u001b[0m, in \u001b[0;36mAnomalyDetector.predict_proba\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    130\u001b[0m discriminator_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_anomaly_score(tensor)\n\u001b[0;32m    131\u001b[0m discriminator_score \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres_weight\n\u001b[1;32m--> 132\u001b[0m reconstruction_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_reconstruction_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m reconstruction_loss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres_weight\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m discriminator_score\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\ml-for-financial-data\\models\\MADGAN.py:143\u001b[0m, in \u001b[0;36mAnomalyDetector.compute_reconstruction_loss\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_reconstruction_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    142\u001b[0m                                 tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 143\u001b[0m     best_reconstruct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_best_reconstruction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (best_reconstruct \u001b[38;5;241m-\u001b[39m tensor)\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\ml-for-financial-data\\models\\MADGAN.py:166\u001b[0m, in \u001b[0;36mAnomalyDetector._generate_best_reconstruction\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    163\u001b[0m     normalized_input \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(generated_samples, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    164\u001b[0m     reconstruction_error \u001b[38;5;241m=\u001b[39m loss_fn(normalized_input,\n\u001b[0;32m    165\u001b[0m                                    normalized_target)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m--> 166\u001b[0m     \u001b[43mreconstruction_error\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-for-financial-data\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-for-financial-data\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_em = total_mv = total_acc = total_precision = total_recall = 0\n",
    "for X, Y, P, PL in test_dl:\n",
    "    prediction = ad.predict(X)\n",
    "    true_positives = true_negatives = false_positives = false_negatives = 0\n",
    "    for i in range(Y.size(0)):\n",
    "        for j in range(Y.size(1)):\n",
    "            cur_label = Y[i][j].item()\n",
    "            cur_pred = prediction[i][j].item()\n",
    "            if cur_label == 1 and cur_pred == 1:\n",
    "                true_positives += 1\n",
    "            elif cur_label == 1 and cur_pred == 0:\n",
    "                false_negatives += 1\n",
    "            elif cur_label == 0 and cur_pred == 1:\n",
    "                false_positives += 1\n",
    "            else:\n",
    "                true_negatives += 1\n",
    "    acc = (true_positives+true_negatives) / (Y.size(0)*Y.size(1))\n",
    "    total_acc += acc\n",
    "    if true_positives+false_positives > 0:\n",
    "        precision = true_positives / (true_positives+false_positives)\n",
    "        total_precision += precision\n",
    "    if true_positives+false_negatives > 0:\n",
    "        recall = true_positives / (true_positives+false_negatives)\n",
    "        total_recall += recall\n",
    "\n",
    "    scores = torch_emmv_scores(ad,X,torch_scoring_function)\n",
    "    print(scores)\n",
    "    \n",
    "    total_em += scores['em']\n",
    "    total_mv += scores['mv']\n",
    "print(total_em/len(test_dl),total_mv/len(test_dl))\n",
    "print(total_acc/len(test_dl),total_precision/len(test_dl),total_recall/len(test_dl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
