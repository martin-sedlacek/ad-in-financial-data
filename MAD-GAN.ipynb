{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8946d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from IPython import display\n",
    "from datetime import datetime\n",
    "import sklearn\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "#import pdb\n",
    "#import json\n",
    "#import sys\n",
    "import random\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from typing import Optional, Protocol, Union, Dict, Iterator, Tuple\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6875aa",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4f87c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_generated_features = 6\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 256\n",
    "lr = 0.001\n",
    "\n",
    "latent_dim = 15\n",
    "hidden_dim = 100\n",
    "seq_length = 30\n",
    "seq_stride = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf1d3fb",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53a53a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdd99(seq_length, seq_step, num_signals):\n",
    "    train = np.load('./data/kdd99_train.npy')\n",
    "    print('load kdd99_train from .npy')\n",
    "    m, n = train.shape  # m=562387, n=35\n",
    "    # normalization\n",
    "    for i in range(n - 1):\n",
    "        # print('i=', i)\n",
    "        A = max(train[:, i])\n",
    "        # print('A=', A)\n",
    "        if A != 0:\n",
    "            train[:, i] /= max(train[:, i])\n",
    "            # scale from -1 to 1\n",
    "            train[:, i] = 2 * train[:, i] - 1\n",
    "        else:\n",
    "            train[:, i] = train[:, i]\n",
    "\n",
    "    samples = train[:, 0:n - 1]\n",
    "    labels = train[:, n - 1]  # the last colummn is label\n",
    "    #############################\n",
    "    ############################\n",
    "    # -- apply PCA dimension reduction for multi-variate GAN-AD -- #\n",
    "    from sklearn.decomposition import PCA\n",
    "    X_n = samples\n",
    "    ####################################\n",
    "    ###################################\n",
    "    # -- the best PC dimension is chosen pc=6 -- #\n",
    "    n_components = num_signals\n",
    "    pca = PCA(n_components, svd_solver='full')\n",
    "    pca.fit(X_n)\n",
    "    ex_var = pca.explained_variance_ratio_\n",
    "    pc = pca.components_\n",
    "    # projected values on the principal component\n",
    "    T_n = np.matmul(X_n, pc.transpose(1, 0))\n",
    "    samples = T_n\n",
    "    # # only for one-dimensional\n",
    "    # samples = T_n.reshape([samples.shape[0], ])\n",
    "    ###########################################\n",
    "    ###########################################\n",
    "    num_samples = (samples.shape[0] - seq_length) // seq_step\n",
    "    aa = np.empty([num_samples, seq_length, num_signals])\n",
    "    bb = np.empty([num_samples, seq_length, 1])\n",
    "\n",
    "    for j in range(num_samples):\n",
    "        bb[j, :, :] = np.reshape(labels[(j * seq_step):(j * seq_step + seq_length)], [-1, 1])\n",
    "        for i in range(num_signals):\n",
    "            aa[j, :, i] = samples[(j * seq_step):(j * seq_step + seq_length), i]\n",
    "\n",
    "    samples = aa\n",
    "    labels = bb\n",
    "\n",
    "    return samples, labels\n",
    "\n",
    "def kdd99_test(seq_length, seq_step, num_signals):\n",
    "    test = np.load('./data/kdd99_test.npy')\n",
    "    print('load kdd99_test from .npy')\n",
    "\n",
    "    m, n = test.shape  # m1=494021, n1=35\n",
    "\n",
    "    for i in range(n - 1):\n",
    "        B = max(test[:, i])\n",
    "        if B != 0:\n",
    "            test[:, i] /= max(test[:, i])\n",
    "            # scale from -1 to 1\n",
    "            test[:, i] = 2 * test[:, i] - 1\n",
    "        else:\n",
    "            test[:, i] = test[:, i]\n",
    "\n",
    "    samples = test[:, 0:n - 1]\n",
    "    labels = test[:, n - 1]\n",
    "    idx = np.asarray(list(range(0, m)))  # record the idx of each point\n",
    "    #############################\n",
    "    ############################\n",
    "    # -- apply PCA dimension reduction for multi-variate GAN-AD -- #\n",
    "    from sklearn.decomposition import PCA\n",
    "    X_a = samples\n",
    "    ####################################\n",
    "    ###################################\n",
    "    # -- the best PC dimension is chosen pc=6 -- #\n",
    "    n_components = num_signals\n",
    "    pca_a = PCA(n_components, svd_solver='full')\n",
    "    pca_a.fit(X_a)\n",
    "    pc_a = pca_a.components_\n",
    "    # projected values on the principal component\n",
    "    T_a = np.matmul(X_a, pc_a.transpose(1, 0))\n",
    "    samples = T_a\n",
    "    # # only for one-dimensional\n",
    "    # samples = T_a.reshape([samples.shape[0], ])\n",
    "    ###########################################\n",
    "    ###########################################\n",
    "    num_samples_t = (samples.shape[0] - seq_length) // seq_step\n",
    "    aa = np.empty([num_samples_t, seq_length, num_signals])\n",
    "    bb = np.empty([num_samples_t, seq_length, 1])\n",
    "    bbb = np.empty([num_samples_t, seq_length, 1])\n",
    "\n",
    "    for j in range(num_samples_t):\n",
    "        bb[j, :, :] = np.reshape(labels[(j * seq_step):(j * seq_step + seq_length)], [-1, 1])\n",
    "        bbb[j, :, :] = np.reshape(idx[(j * seq_step):(j * seq_step + seq_length)], [-1, 1])\n",
    "        for i in range(num_signals):\n",
    "            aa[j, :, i] = samples[(j * seq_step):(j * seq_step + seq_length), i]\n",
    "\n",
    "    samples = aa\n",
    "    labels = bb\n",
    "    index = bbb\n",
    "\n",
    "    return samples, labels, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40680c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load kdd99_train from .npy\n",
      "load kdd99_test from .npy\n"
     ]
    }
   ],
   "source": [
    "train_samples, train_labels = kdd99(seq_length, seq_stride, num_generated_features)\n",
    "test_samples, test_labels, index = kdd99_test(seq_length, seq_stride, num_generated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e8eb369",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.Tensor(train_samples) \n",
    "train_y = torch.Tensor(train_labels) \n",
    "train_data = torch.utils.data.TensorDataset(train_x,train_y)\n",
    "train_dl = torch.utils.data.DataLoader(train_data, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "test_x = torch.Tensor(test_samples) \n",
    "test_y = torch.Tensor(test_labels) \n",
    "test_data = torch.utils.data.TensorDataset(test_x,test_y)\n",
    "test_dl = torch.utils.data.DataLoader(test_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048114d2",
   "metadata": {},
   "source": [
    "# Complementary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f02a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 0) -> None:\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc4b5e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- sample Z from latent space --- #\n",
    "def sample_Z(batch_size, seq_length, latent_dim, use_time=False, use_noisy_time=False):\n",
    "    sample = np.float32(np.random.normal(size=[batch_size, seq_length, latent_dim]))\n",
    "    if use_time:\n",
    "        print('WARNING: use_time has different semantics')\n",
    "        sample[:, :, 0] = np.linspace(0, 1.0 / seq_length, num=seq_length)\n",
    "    return torch.Tensor(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f525bd48",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a562c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,latent_space_dim: int,hidden_units: int,output_dim: int,n_lstm_layers: int = 2) -> None:\n",
    "        super().__init__()\n",
    "        self.latent_space_dim = latent_space_dim\n",
    "        self.hidden_units = hidden_units\n",
    "        self.n_lstm_layers = n_lstm_layers\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.latent_space_dim,\n",
    "                            hidden_size=self.hidden_units,\n",
    "                            num_layers=self.n_lstm_layers,\n",
    "                            batch_first=True,\n",
    "                            dropout=.1)\n",
    "\n",
    "        self.linear = nn.Linear(in_features=self.hidden_units,\n",
    "                                out_features=self.output_dim)\n",
    "        \n",
    "        nn.init.trunc_normal_(self.linear.bias)\n",
    "        nn.init.trunc_normal_(self.linear.weight)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        rnn_output, _ = self.lstm(x)\n",
    "        return self.linear(rnn_output)\n",
    "\n",
    "    def save(self, fpath: Union[Path, str]) -> None:\n",
    "        chkp = {\n",
    "            \"config\": {\n",
    "                \"latent_space_dim\": self.latent_space_dim,\n",
    "                \"hidden_units\": self.hidden_units,\n",
    "                \"n_lstm_layers\": self.n_lstm_layers,\n",
    "                \"output_dim\": self.output_dim\n",
    "            },\n",
    "            \"weights\": self.state_dict(),\n",
    "        }\n",
    "        torch.save(chkp, fpath)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_pretrained(\n",
    "            cls,\n",
    "            fpath: Union[Path, str],\n",
    "            map_location: Optional[torch.device] = None) -> \"Generator\":\n",
    "        chkp = torch.load(fpath, map_location=map_location)\n",
    "        model = cls(**chkp.pop(\"config\"))\n",
    "        model.load_state_dict(chkp.pop(\"weights\"))\n",
    "        model.eval()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e689be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,input_dim, hidden_units, n_lstm_layers: int = 2,add_batch_mean: bool = True) -> None:\n",
    "        super().__init__()\n",
    "        self.add_batch_mean = add_batch_mean\n",
    "        self.hidden_units = hidden_units\n",
    "        self.input_dim = input_dim\n",
    "        self.n_lstm_layers = n_lstm_layers\n",
    "\n",
    "        extra_features = self.hidden_units if self.add_batch_mean else 0\n",
    "        self.lstm = nn.LSTM(input_size=self.input_dim,\n",
    "                            hidden_size=self.hidden_units + extra_features,\n",
    "                            num_layers=self.n_lstm_layers,\n",
    "                            batch_first=True,\n",
    "                            dropout=.1)\n",
    "\n",
    "        self.linear = nn.Linear(in_features=self.hidden_units + extra_features,\n",
    "                                out_features=1)\n",
    "        nn.init.trunc_normal_(self.linear.bias)\n",
    "        nn.init.trunc_normal_(self.linear.weight)\n",
    "\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.add_batch_mean:\n",
    "            bs = x.size(0)\n",
    "            batch_mean = x.mean(0, keepdim=True).repeat(bs, 1, 1)\n",
    "            x = torch.cat([x, batch_mean], dim=-1)\n",
    "\n",
    "        rnn_output, _ = self.lstm(x)\n",
    "        return self.activation(self.linear(rnn_output))\n",
    "\n",
    "    def save(self, fpath: Union[Path, str]) -> None:\n",
    "        chkp = {\n",
    "            \"config\": {\n",
    "                \"add_batch_mean\": self.add_batch_mean,\n",
    "                \"hidden_units\": self.hidden_units,\n",
    "                \"input_dim\": self.input_dim,\n",
    "                \"n_lstm_layers\": self.n_lstm_layers\n",
    "            },\n",
    "            \"weights\": self.state_dict(),\n",
    "        }\n",
    "        torch.save(chkp, fpath)\n",
    "        \n",
    "    @classmethod\n",
    "    def from_pretrained(\n",
    "            cls,\n",
    "            fpath: Union[Path, str],\n",
    "            map_location: Optional[torch.device] = None) -> \"Discriminator\":\n",
    "        chkp = torch.load(fpath, map_location=map_location)\n",
    "        model = cls(**chkp.pop(\"config\"))\n",
    "        model.load_state_dict(chkp.pop(\"weights\"))\n",
    "        model.eval()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be8a499",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "723af568",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58c7339d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (lstm): LSTM(15, 100, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (linear): Linear(in_features=100, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator(\n",
    "    latent_space_dim=latent_dim,\n",
    "    hidden_units=hidden_dim,\n",
    "    output_dim=num_generated_features)\n",
    "generator.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c29f5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (lstm): LSTM(6, 100, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = Discriminator(input_dim=num_generated_features,\n",
    "    hidden_units=hidden_dim,\n",
    "    add_batch_mean=False)\n",
    "discriminator.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a7ac0d",
   "metadata": {},
   "source": [
    "# Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d4ba84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(inputs, targets):\n",
    "    return nn.BCELoss()(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5b9354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_optim = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "generator_optim = torch.optim.Adam(generator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eac6fa3",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4aee653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(G, D, loss_fn, real_dl, normal_label: int = 0, anomaly_label: int = 1) -> Dict[str, float]: \n",
    "    metric_accum = {\n",
    "        \"D_loss\": 0,\n",
    "        \"G_acc\": 0,\n",
    "        \"D_acc\": 0\n",
    "    }\n",
    "    batch_count = 0\n",
    "    for X, Y in real_dl:\n",
    "        bs = X.size(0)\n",
    "        \n",
    "        # Samples\n",
    "        real_samples = X.to(DEVICE)\n",
    "        latent_samples = sample_Z(bs, seq_length, latent_dim).to(DEVICE)\n",
    "        fake_samples = G(latent_samples)\n",
    "\n",
    "        # Labels\n",
    "        real_labels = Y.to(DEVICE)\n",
    "        fake_labels = torch.zeros(bs, seq_length, 1).to(DEVICE)\n",
    "        all_labels = torch.cat([real_labels, fake_labels])\n",
    "\n",
    "        # Try to classify the real and generated samples\n",
    "        real_d = D(real_samples)\n",
    "        fake_d = D(fake_samples.detach())\n",
    "        all_d = torch.cat([real_d, fake_d]).to(DEVICE)\n",
    "\n",
    "        # Discriminator tries to identify the true nature of each sample (anomaly or normal)\n",
    "        d_real_loss = loss_fn(real_d.view(-1), real_labels.view(-1))\n",
    "        d_fake_loss = loss_fn(fake_d.view(-1), fake_labels.view(-1))\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "\n",
    "        discriminator_acc = ((all_d > .5) == all_labels).float()\n",
    "        discriminator_acc = discriminator_acc.sum().div(bs*seq_length)\n",
    "\n",
    "        generator_acc = ((fake_d > .5) == real_labels).float()\n",
    "        generator_acc = generator_acc.sum().div(bs*seq_length)\n",
    "\n",
    "        metric_accum[\"D_loss\"] += d_loss.item()\n",
    "        metric_accum[\"D_acc\"] += discriminator_acc.item()\n",
    "        metric_accum[\"G_acc\"] += generator_acc.item()\n",
    "        batch_count += 1\n",
    "    for key in metric_accum.keys():\n",
    "        metric_accum[key] = metric_accum[key]/batch_count\n",
    "    print(\"Evaluation metrics:\", metric_accum)\n",
    "    return metric_accum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e32cf84",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e788909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(G, D, loss_fn, real_dl, G_optimizer, D_optimizer, normal_label: int = 0, anomaly_label: int = 1, epoch: int = 0, log_every: int = 30) -> None:\n",
    "    G.train()\n",
    "    D.train()\n",
    "    metric_accum = {\n",
    "    \"generator_loss\": 0,\n",
    "    \"discriminator_loss_real\": 0,\n",
    "    \"discriminator_loss_fake\": 0,\n",
    "    }\n",
    "    batch_count = 0\n",
    "    for i, (X,Y) in enumerate(real_dl):\n",
    "        bs = X.size(0)\n",
    "        \n",
    "        # Samples\n",
    "        real_samples = X.to(DEVICE)\n",
    "        latent_samples = sample_Z(bs, seq_length, latent_dim).to(DEVICE)\n",
    "        fake_samples = G(latent_samples)\n",
    "\n",
    "        # Labels\n",
    "        real_labels = Y.to(DEVICE)\n",
    "        fake_labels = torch.full((bs, seq_length, 1), anomaly_label).float().to(DEVICE)\n",
    "        all_labels = torch.cat([real_labels, fake_labels])\n",
    "        \n",
    "        # Discriminator update\n",
    "        D_optimizer.zero_grad()\n",
    "        real_d = D(real_samples)\n",
    "        fake_d = D(fake_samples.detach())\n",
    "        all_d = torch.cat([real_d, fake_d])\n",
    "        \n",
    "        d_loss_real = loss_fn(real_d.view(-1), real_labels.view(-1))\n",
    "        d_loss_fake = loss_fn(fake_d.view(-1), fake_labels.view(-1))\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        \n",
    "        D_optimizer.step()\n",
    "\n",
    "        #Genertor update\n",
    "        G_optimizer.zero_grad()\n",
    "        fake_d = D(fake_samples)\n",
    "        g_loss = loss_fn(fake_d.view(-1), real_labels.view(-1))\n",
    "        g_loss.backward()\n",
    "        G_optimizer.step()\n",
    "        \n",
    "        # Save metrics\n",
    "        metric_accum['generator_loss'] += g_loss.item()\n",
    "        metric_accum['discriminator_loss_real'] += d_loss_real.item()\n",
    "        metric_accum['discriminator_loss_fake'] += d_loss_fake.item()\n",
    "        batch_count += 1\n",
    "    D.zero_grad()\n",
    "    G.zero_grad()\n",
    "    out = 'G_loss: ' + str(metric_accum['generator_loss']/batch_count) + ', ' + 'D_loss_real: ' + str(metric_accum['discriminator_loss_real']/batch_count) + ', ' + 'D_loss_fake: ' + str(metric_accum['discriminator_loss_fake']/batch_count)\n",
    "    print('Epoch ' + str(epoch) + 'training:')\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8e7ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch_size, seq_length, latent_dim, train_dl, test_dl, D, G, D_optim, G_optim, loss_fn,\n",
    "          model_dir: Path = Path(\"models/madgan\")) -> None:\n",
    "    set_seed(random_seed)\n",
    "    model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_epoch(G, D, loss_fn, train_dl, generator_optim, discriminator_optim, normal_label=0, anomaly_label=1, epoch=epoch)\n",
    "        evaluate(G, D, loss_fn, test_dl, normal_label=0, anomaly_label=1)\n",
    "\n",
    "        G.save(model_dir / f\"generator_{epoch}.pt\")\n",
    "        D.save(model_dir / f\"discriminator_{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f39b695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0training:\n",
      "G_loss: 2.6426471847024833, D_loss_real: 0.6577470123090527, D_loss_fake: 0.680391707948663\n",
      "Evaluation metrics: {'D_loss': 4.524801220918566, 'G_acc': 0.7562280367538718, 'D_acc': 0.34170340013164313}\n",
      "Epoch 1training:\n",
      "G_loss: 2.8840485973791643, D_loss_real: 0.46929060225798325, D_loss_fake: 0.3836389892649921\n",
      "Evaluation metrics: {'D_loss': 4.165808588729621, 'G_acc': 0.7902210044911026, 'D_acc': 0.3741761211672595}\n",
      "Epoch 2training:\n",
      "G_loss: 2.1145877041599968, D_loss_real: 0.5924394269219854, D_loss_fake: 0.46860516633499755\n",
      "Evaluation metrics: {'D_loss': 1.9284354188899302, 'G_acc': 0.7308149179491972, 'D_acc': 0.8842415930075966}\n",
      "Epoch 3training:\n",
      "G_loss: 1.9815886093811554, D_loss_real: 0.48248353075574746, D_loss_fake: 0.4688820813528516\n",
      "Evaluation metrics: {'D_loss': 6.067451795765773, 'G_acc': 0.7175702901238604, 'D_acc': 0.2713425062944234}\n",
      "Epoch 4training:\n",
      "G_loss: 2.119596509229053, D_loss_real: 0.6370347268879414, D_loss_fake: 0.4514860008927909\n",
      "Evaluation metrics: {'D_loss': 3.3775651584635127, 'G_acc': 0.6373620654789277, 'D_acc': 0.6343885057948414}\n",
      "Epoch 5training:\n",
      "G_loss: 1.9710903086445548, D_loss_real: 0.4497144050049511, D_loss_fake: 0.38286633884364907\n",
      "Evaluation metrics: {'D_loss': 3.63974671969142, 'G_acc': 0.5111106993929709, 'D_acc': 0.8588487717462945}\n",
      "Epoch 6training:\n",
      "G_loss: 2.1460186646743256, D_loss_real: 0.48424164510586043, D_loss_fake: 0.39640976481816986\n",
      "Evaluation metrics: {'D_loss': 4.308593677115564, 'G_acc': 0.648883213728203, 'D_acc': 0.4690338056631039}\n",
      "Epoch 7training:\n",
      "G_loss: 2.094515892185948, D_loss_real: 0.44757754025472835, D_loss_fake: 0.4193696502934803\n",
      "Evaluation metrics: {'D_loss': 9.213129319057563, 'G_acc': 0.7718169649802341, 'D_acc': 0.15464947303187662}\n",
      "Epoch 8training:\n",
      "G_loss: 2.2798012069680476, D_loss_real: 0.4998616419901902, D_loss_fake: 0.3514333716001023\n",
      "Evaluation metrics: {'D_loss': 3.0451805665703016, 'G_acc': 0.763176937872264, 'D_acc': 0.30384440943984786}\n",
      "Epoch 9training:\n",
      "G_loss: 1.7703297623179175, D_loss_real: 0.5259429757906632, D_loss_fake: 0.39805986034599217\n",
      "Evaluation metrics: {'D_loss': 3.097309803097977, 'G_acc': 0.7577656521775562, 'D_acc': 0.8714826954769964}\n",
      "Epoch 10training:\n",
      "G_loss: 1.7040029658512637, D_loss_real: 0.4674612001769922, D_loss_fake: 0.406311470405622\n",
      "Evaluation metrics: {'D_loss': 3.7491625948891123, 'G_acc': 0.7692470746259615, 'D_acc': 0.7068767670754323}\n",
      "Epoch 11training:\n",
      "G_loss: 2.3920761731537907, D_loss_real: 0.3703634332188151, D_loss_fake: 0.27898278547958894\n",
      "Evaluation metrics: {'D_loss': 2.7663404169477945, 'G_acc': 0.7249819473821882, 'D_acc': 0.8844416803183334}\n",
      "Epoch 12training:\n",
      "G_loss: 1.9805992343209007, D_loss_real: 0.4161867984739894, D_loss_fake: 0.274508280611851\n",
      "Evaluation metrics: {'D_loss': 3.4547084217862145, 'G_acc': 0.7467782296664974, 'D_acc': 0.874235436436117}\n",
      "Epoch 13training:\n",
      "G_loss: 1.9921216040849685, D_loss_real: 0.38551756103777074, D_loss_fake: 0.27314674011008305\n",
      "Evaluation metrics: {'D_loss': 5.809191291196359, 'G_acc': 0.7792435876079329, 'D_acc': 0.36975452517173757}\n",
      "Epoch 14training:\n",
      "G_loss: 2.222706394574859, D_loss_real: 0.37430838671597566, D_loss_fake: 0.2569393301551992\n",
      "Evaluation metrics: {'D_loss': 2.817483089130777, 'G_acc': 0.7832659091510921, 'D_acc': 0.8879788137316086}\n",
      "Epoch 15training:\n",
      "G_loss: 2.248754679072987, D_loss_real: 0.35613403587856074, D_loss_fake: 0.20595781650732864\n",
      "Evaluation metrics: {'D_loss': 2.768617348349774, 'G_acc': 0.7547321019240611, 'D_acc': 0.9262674728051369}\n",
      "Epoch 16training:\n",
      "G_loss: 2.0772245911034672, D_loss_real: 0.40915934332985093, D_loss_fake: 0.26859106468883426\n",
      "Evaluation metrics: {'D_loss': 2.924887395275689, 'G_acc': 0.783405954790316, 'D_acc': 0.47379203650309015}\n",
      "Epoch 17training:\n",
      "G_loss: 2.4724708416245202, D_loss_real: 0.34311408208767796, D_loss_fake: 0.1885729143904014\n",
      "Evaluation metrics: {'D_loss': 3.359221526378177, 'G_acc': 0.7985109336712818, 'D_acc': 0.9126804003327931}\n",
      "Epoch 18training:\n",
      "G_loss: 2.051542836969549, D_loss_real: 0.3495629730211063, D_loss_fake: 0.2198694085194306\n",
      "Evaluation metrics: {'D_loss': 3.057684553719555, 'G_acc': 0.7938207613757855, 'D_acc': 0.5012486875829302}\n",
      "Epoch 19training:\n",
      "G_loss: 2.34350519397042, D_loss_real: 0.3151556336193938, D_loss_fake: 0.17950520129366354\n",
      "Evaluation metrics: {'D_loss': 3.146797202411711, 'G_acc': 0.7941556623630187, 'D_acc': 0.6452039393832801}\n",
      "Epoch 20training:\n",
      "G_loss: 2.414837372573939, D_loss_real: 0.3232301345518367, D_loss_fake: 0.1941508051007986\n",
      "Evaluation metrics: {'D_loss': 2.8717626957078055, 'G_acc': 0.76411750289211, 'D_acc': 0.8898505857262586}\n",
      "Epoch 21training:\n",
      "G_loss: 2.507803929935802, D_loss_real: 0.31607639674012633, D_loss_fake: 0.1635444745082747\n",
      "Evaluation metrics: {'D_loss': 3.5307709194835604, 'G_acc': 0.7844235735892323, 'D_acc': 0.47062323404562906}\n",
      "Epoch 22training:\n",
      "G_loss: 2.644949135455218, D_loss_real: 0.3115705023921857, D_loss_fake: 0.19067418292503466\n",
      "Evaluation metrics: {'D_loss': 4.8338495177926175, 'G_acc': 0.786193773102189, 'D_acc': 0.45719034981387885}\n",
      "Epoch 23training:\n",
      "G_loss: 2.7915823150764814, D_loss_real: 0.3330822509819303, D_loss_fake: 0.19742221713743427\n",
      "Evaluation metrics: {'D_loss': 2.6995537367509437, 'G_acc': 0.8029267462513318, 'D_acc': 0.9341449326319243}\n",
      "Epoch 24training:\n",
      "G_loss: 2.681220768256621, D_loss_real: 0.29522589363411744, D_loss_fake: 0.13441388601945206\n",
      "Evaluation metrics: {'D_loss': 3.187080002819318, 'G_acc': 0.8029475825909016, 'D_acc': 0.939049330182914}\n",
      "Epoch 25training:\n",
      "G_loss: 2.106795235113664, D_loss_real: 0.3199139404147652, D_loss_fake: 0.1620189837434075\n",
      "Evaluation metrics: {'D_loss': 2.6213756682341582, 'G_acc': 0.7878613090866433, 'D_acc': 0.9560740080136092}\n",
      "Epoch 26training:\n",
      "G_loss: 2.2117303880778225, D_loss_real: 0.3207622673235495, D_loss_fake: 0.1846219152212143\n",
      "Evaluation metrics: {'D_loss': 3.0495118489537214, 'G_acc': 0.7525815148234676, 'D_acc': 0.8192223876405874}\n",
      "Epoch 27training:\n",
      "G_loss: 2.706576777046377, D_loss_real: 0.3814559003867378, D_loss_fake: 0.29185170749710365\n",
      "Evaluation metrics: {'D_loss': 4.094543431089332, 'G_acc': 0.7646485515170456, 'D_acc': 0.7215020152416871}\n",
      "Epoch 28training:\n",
      "G_loss: 2.7933033802292564, D_loss_real: 0.3717548698652536, D_loss_fake: 0.2547096704217521\n",
      "Evaluation metrics: {'D_loss': 4.286643878783587, 'G_acc': 0.6712964133123042, 'D_acc': 0.6367425127968269}\n",
      "Epoch 29training:\n",
      "G_loss: 2.654864445599643, D_loss_real: 0.3260371532883834, D_loss_fake: 0.20900435075163842\n",
      "Evaluation metrics: {'D_loss': 3.7291139296299436, 'G_acc': 0.7996118828826801, 'D_acc': 0.4982476258274033}\n",
      "Epoch 30training:\n",
      "G_loss: 2.486634181846272, D_loss_real: 0.31273031065409834, D_loss_fake: 0.1977258747612888\n",
      "Evaluation metrics: {'D_loss': 3.0870304280612135, 'G_acc': 0.779186925759124, 'D_acc': 0.7201133318477035}\n",
      "Epoch 31training:\n",
      "G_loss: 2.1655490918592974, D_loss_real: 0.3732160012407059, D_loss_fake: 0.2714575452899391\n",
      "Evaluation metrics: {'D_loss': 3.297086930645562, 'G_acc': 0.7629781442216641, 'D_acc': 0.7514058395525335}\n",
      "Epoch 32training:\n",
      "G_loss: 2.0754479668357155, D_loss_real: 0.4081535367041149, D_loss_fake: 0.3086583995344964\n",
      "Evaluation metrics: {'D_loss': 3.5831128822089475, 'G_acc': 0.7510652442322803, 'D_acc': 0.44505694404321633}\n",
      "Epoch 33training:\n",
      "G_loss: 2.1105237012559717, D_loss_real: 0.3323902345114303, D_loss_fake: 0.19612515101378614\n",
      "Evaluation metrics: {'D_loss': 3.2180815904251654, 'G_acc': 0.7970886291414885, 'D_acc': 0.724260245840707}\n",
      "Epoch 34training:\n",
      "G_loss: 2.430393946170807, D_loss_real: 0.3224794752028009, D_loss_fake: 0.18032060832801192\n",
      "Evaluation metrics: {'D_loss': 3.2068818801425283, 'G_acc': 0.8012440191585465, 'D_acc': 0.6528976235895808}\n",
      "Epoch 35training:\n",
      "G_loss: 2.468688886815851, D_loss_real: 0.32066616532075304, D_loss_fake: 0.1541873819448731\n",
      "Evaluation metrics: {'D_loss': 3.31537589755083, 'G_acc': 0.7989324703704025, 'D_acc': 0.8872586838090358}\n",
      "Epoch 36training:\n",
      "G_loss: 2.4058916129849175, D_loss_real: 0.29878213457149366, D_loss_fake: 0.16642648882486605\n",
      "Evaluation metrics: {'D_loss': 2.3878814210545833, 'G_acc': 0.7630692303489527, 'D_acc': 0.9992260597839256}\n",
      "Epoch 37training:\n",
      "G_loss: 1.9420743627981707, D_loss_real: 0.40114307660524817, D_loss_fake: 0.29455255791544915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics: {'D_loss': 2.0395104100667134, 'G_acc': 0.7402330250551663, 'D_acc': 0.9481771464406518}\n",
      "Epoch 38training:\n",
      "G_loss: 1.9732234179973602, D_loss_real: 0.404508914231238, D_loss_fake: 0.30722422152757645\n",
      "Evaluation metrics: {'D_loss': 3.452962250289522, 'G_acc': 0.7603456573705599, 'D_acc': 0.7396899185341257}\n",
      "Epoch 39training:\n",
      "G_loss: 1.9203370289369064, D_loss_real: 0.3838494819165631, D_loss_fake: 0.32186033007773485\n",
      "Evaluation metrics: {'D_loss': 3.8649214926161295, 'G_acc': 0.7375693744328355, 'D_acc': 0.369807144559418}\n",
      "Epoch 40training:\n",
      "G_loss: 1.6941676684401252, D_loss_real: 0.45999550175937737, D_loss_fake: 0.4033679587597197\n",
      "Evaluation metrics: {'D_loss': 2.568090862560766, 'G_acc': 0.7363751988105206, 'D_acc': 0.9294062838576}\n",
      "Epoch 41training:\n",
      "G_loss: 2.030965313586322, D_loss_real: 0.3925564662976698, D_loss_fake: 0.3334751819345084\n",
      "Evaluation metrics: {'D_loss': 2.611526700499144, 'G_acc': 0.7014193222158314, 'D_acc': 1.0130544321061417}\n",
      "Epoch 42training:\n",
      "G_loss: 1.7758517519994215, D_loss_real: 0.43882793714715673, D_loss_fake: 0.3440352436832406\n",
      "Evaluation metrics: {'D_loss': 2.7419086960313233, 'G_acc': 0.7788976496326799, 'D_acc': 0.8282887856017586}\n",
      "Epoch 43training:\n",
      "G_loss: 1.7411585591056131, D_loss_real: 0.49366550761359657, D_loss_fake: 0.38522605862129816\n",
      "Evaluation metrics: {'D_loss': 2.6366757593006667, 'G_acc': 0.7339696722404326, 'D_acc': 0.8968898554771675}\n",
      "Epoch 44training:\n",
      "G_loss: 1.4507242040200667, D_loss_real: 0.5718500121581284, D_loss_fake: 0.49515779655088077\n",
      "Evaluation metrics: {'D_loss': 2.4438142572659904, 'G_acc': 0.577059637234001, 'D_acc': 0.6386250662062453}\n",
      "Epoch 45training:\n",
      "G_loss: 1.6248423782261936, D_loss_real: 0.49868337014182046, D_loss_fake: 0.43435644920576705\n",
      "Evaluation metrics: {'D_loss': 2.147063228750476, 'G_acc': 0.6518788151636025, 'D_acc': 1.0918819597039198}\n",
      "Epoch 46training:\n",
      "G_loss: 1.49800952185284, D_loss_real: 0.5195847255601125, D_loss_fake: 0.4990671872415326\n",
      "Evaluation metrics: {'D_loss': 2.2484587986852222, 'G_acc': 0.7179466290640707, 'D_acc': 1.0022671437325255}\n",
      "Epoch 47training:\n",
      "G_loss: 1.7503873881968586, D_loss_real: 0.5052008978260512, D_loss_fake: 0.3890313577245582\n",
      "Evaluation metrics: {'D_loss': 3.124263340945071, 'G_acc': 0.7988247576536408, 'D_acc': 0.8519398817609165}\n",
      "Epoch 48training:\n",
      "G_loss: 2.187346945025704, D_loss_real: 0.37215528653257274, D_loss_fake: 0.30294922881505704\n",
      "Evaluation metrics: {'D_loss': 2.462247957837396, 'G_acc': 0.73395444275184, 'D_acc': 0.93794941867417}\n",
      "Epoch 49training:\n",
      "G_loss: 1.7624553675001318, D_loss_real: 0.5171127076514742, D_loss_fake: 0.40788923393596305\n",
      "Evaluation metrics: {'D_loss': 2.9073629651044937, 'G_acc': 0.7566939540632031, 'D_acc': 0.9809736203537395}\n",
      "Epoch 50training:\n",
      "G_loss: 2.134974272142757, D_loss_real: 0.39594574128700927, D_loss_fake: 0.3286638480695811\n",
      "Evaluation metrics: {'D_loss': 2.359837003322463, 'G_acc': 0.7805296847683624, 'D_acc': 0.89937221166229}\n",
      "Epoch 51training:\n",
      "G_loss: 1.764236493544145, D_loss_real: 0.48359301232478835, D_loss_fake: 0.3855862061408433\n",
      "Evaluation metrics: {'D_loss': 2.3095528177646774, 'G_acc': 0.7342138475318647, 'D_acc': 0.9319306049939882}\n",
      "Epoch 52training:\n",
      "G_loss: 1.4955171522769062, D_loss_real: 0.5332909527827393, D_loss_fake: 0.42721506824547595\n",
      "Evaluation metrics: {'D_loss': 2.320405974906961, 'G_acc': 0.7153773198936887, 'D_acc': 1.060998434152628}\n",
      "Epoch 53training:\n",
      "G_loss: 1.4932655740867962, D_loss_real: 0.5158751448108392, D_loss_fake: 0.43957160013643176\n",
      "Evaluation metrics: {'D_loss': 2.382886765534396, 'G_acc': 0.7406433904881304, 'D_acc': 1.0276659508983705}\n",
      "Epoch 54training:\n",
      "G_loss: 1.6569975500757044, D_loss_real: 0.47871900390494954, D_loss_fake: 0.4055200955407186\n",
      "Evaluation metrics: {'D_loss': 2.2879080037378894, 'G_acc': 0.7397807865099586, 'D_acc': 0.9763773008022901}\n",
      "Epoch 55training:\n",
      "G_loss: 1.4759538951245221, D_loss_real: 0.49761051464487205, D_loss_fake: 0.4342937590723688\n",
      "Evaluation metrics: {'D_loss': 2.4129224706807904, 'G_acc': 0.7237866837434818, 'D_acc': 1.022732927275754}\n",
      "Epoch 56training:\n",
      "G_loss: 1.3807371459224007, D_loss_real: 0.5219982898709449, D_loss_fake: 0.4884322408248078\n",
      "Evaluation metrics: {'D_loss': 2.123501378019857, 'G_acc': 0.6887289322719673, 'D_acc': 1.1043877215583089}\n",
      "Epoch 57training:\n",
      "G_loss: 1.409700950438326, D_loss_real: 0.525205607729202, D_loss_fake: 0.4657948114655235\n",
      "Evaluation metrics: {'D_loss': 2.7303601583668606, 'G_acc': 0.7588460530718991, 'D_acc': 0.5796916037411888}\n",
      "Epoch 58training:\n",
      "G_loss: 1.5295520907098596, D_loss_real: 0.5429808765649795, D_loss_fake: 0.44949611499905584\n",
      "Evaluation metrics: {'D_loss': 2.136015046445817, 'G_acc': 0.6373199717059654, 'D_acc': 1.1987291521976648}\n",
      "Epoch 59training:\n",
      "G_loss: 1.6761233294552023, D_loss_real: 0.47892950409176677, D_loss_fake: 0.43595208789814605\n",
      "Evaluation metrics: {'D_loss': 2.6482322259270465, 'G_acc': 0.7993845485326945, 'D_acc': 0.8983682972062959}\n",
      "Epoch 60training:\n",
      "G_loss: 1.402810850739479, D_loss_real: 0.5218993721021847, D_loss_fake: 0.46286050880497154\n",
      "Evaluation metrics: {'D_loss': 2.849757242079226, 'G_acc': 0.6900128995507492, 'D_acc': 0.725075788757344}\n",
      "Epoch 61training:\n",
      "G_loss: 1.7227673568508841, D_loss_real: 0.489795143563639, D_loss_fake: 0.41137537990104067\n",
      "Evaluation metrics: {'D_loss': 2.294169712560782, 'G_acc': 0.7093950987943096, 'D_acc': 1.0665897693427115}\n",
      "Epoch 62training:\n",
      "G_loss: 1.5325385800816795, D_loss_real: 0.4899489127099514, D_loss_fake: 0.4457915742966262\n",
      "Evaluation metrics: {'D_loss': 2.105300310362188, 'G_acc': 0.6909275031769214, 'D_acc': 1.0867097315238547}\n",
      "Epoch 63training:\n",
      "G_loss: 1.4723940681327472, D_loss_real: 0.5454464012926276, D_loss_fake: 0.47332263853062284\n",
      "Evaluation metrics: {'D_loss': 1.8020504811884825, 'G_acc': 0.5709195445856282, 'D_acc': 1.302465507866805}\n",
      "Epoch 64training:\n",
      "G_loss: 1.0386166206815026, D_loss_real: 0.6218893596394496, D_loss_fake: 0.6122535847804763\n",
      "Evaluation metrics: {'D_loss': 1.6559632618192563, 'G_acc': 0.5810188884253329, 'D_acc': 1.2887759279710642}\n",
      "Epoch 65training:\n",
      "G_loss: 1.0636312590403991, D_loss_real: 0.5833443870937283, D_loss_fake: 0.5737539810213176\n",
      "Evaluation metrics: {'D_loss': 2.281735213927037, 'G_acc': 0.7571890273667061, 'D_acc': 1.000660034388767}\n",
      "Epoch 66training:\n",
      "G_loss: 1.4384146541357041, D_loss_real: 0.5281906851482663, D_loss_fake: 0.4596005223014138\n",
      "Evaluation metrics: {'D_loss': 2.066342647211539, 'G_acc': 0.7368852843197516, 'D_acc': 1.0291801171058819}\n",
      "Epoch 67training:\n",
      "G_loss: 1.0439668479290876, D_loss_real: 0.6153320851651105, D_loss_fake: 0.5892099552533844\n",
      "Evaluation metrics: {'D_loss': 1.8429030136740887, 'G_acc': 0.5833050222594504, 'D_acc': 1.2820296086795588}\n",
      "Epoch 68training:\n",
      "G_loss: 1.5312751043926587, D_loss_real: 0.4490645511668514, D_loss_fake: 0.38874280188571325\n",
      "Evaluation metrics: {'D_loss': 2.865059200346161, 'G_acc': 0.8022986648717673, 'D_acc': 0.924870503702324}\n",
      "Epoch 69training:\n",
      "G_loss: 1.8306970563801852, D_loss_real: 0.3953519942154261, D_loss_fake: 0.28020907142622903\n",
      "Evaluation metrics: {'D_loss': 2.3662088238513532, 'G_acc': 0.7591125973032238, 'D_acc': 0.9995453275276898}\n",
      "Epoch 70training:\n",
      "G_loss: 1.4178316045891155, D_loss_real: 0.511806503674862, D_loss_fake: 0.454871169951829\n",
      "Evaluation metrics: {'D_loss': 2.2846601596150373, 'G_acc': 0.7955927614344602, 'D_acc': 0.9439977619536414}\n",
      "Epoch 71training:\n",
      "G_loss: 1.7390971823172137, D_loss_real: 0.3587251431710849, D_loss_fake: 0.2168154820122502\n",
      "Evaluation metrics: {'D_loss': 2.602437250972412, 'G_acc': 0.8029698399101399, 'D_acc': 0.9350981625868249}\n",
      "Epoch 72training:\n",
      "G_loss: 1.8928842582485892, D_loss_real: 0.360080378214744, D_loss_fake: 0.19074654619802128\n",
      "Evaluation metrics: {'D_loss': 2.5854932026541912, 'G_acc': 0.8029934472375467, 'D_acc': 0.9347117223579031}\n",
      "Epoch 73training:\n",
      "G_loss: 1.9276213309981607, D_loss_real: 0.39599792253363625, D_loss_fake: 0.2303933078592474\n",
      "Evaluation metrics: {'D_loss': 2.1790776746878353, 'G_acc': 0.7836527073553189, 'D_acc': 0.9701243910861294}\n",
      "Epoch 74training:\n",
      "G_loss: 1.675003012743863, D_loss_real: 0.42150091333314776, D_loss_fake: 0.2566580433737148\n",
      "Evaluation metrics: {'D_loss': 2.2343364428979746, 'G_acc': 0.7783405787740965, 'D_acc': 0.9788741991888983}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75training:\n",
      "G_loss: 1.6488267909396779, D_loss_real: 0.45174915978727354, D_loss_fake: 0.3169500908391042\n",
      "Evaluation metrics: {'D_loss': 2.3962712275549536, 'G_acc': 0.7854230499638177, 'D_acc': 0.9692654160425608}\n",
      "Epoch 76training:\n",
      "G_loss: 1.7350665520537982, D_loss_real: 0.43364922074939716, D_loss_fake: 0.27788718437606635\n",
      "Evaluation metrics: {'D_loss': 2.4108618812857516, 'G_acc': 0.7875066390791859, 'D_acc': 0.9656543154076437}\n",
      "Epoch 77training:\n",
      "G_loss: 1.5996628587896173, D_loss_real: 0.4956960573580793, D_loss_fake: 0.39395454519174317\n",
      "Evaluation metrics: {'D_loss': 2.0266853447405166, 'G_acc': 0.7863158862362254, 'D_acc': 0.9671651127366977}\n",
      "Epoch 78training:\n",
      "G_loss: 1.5747747402299535, D_loss_real: 0.4772223069417206, D_loss_fake: 0.4181711177256974\n",
      "Evaluation metrics: {'D_loss': 1.9424785536187918, 'G_acc': 0.7275563579226405, 'D_acc': 1.0637188411747236}\n",
      "Epoch 79training:\n",
      "G_loss: 1.498180402950807, D_loss_real: 0.4903134814124893, D_loss_fake: 0.41442872773517264\n",
      "Evaluation metrics: {'D_loss': 1.9196164855067595, 'G_acc': 0.5564017566065714, 'D_acc': 1.3294109005693326}\n",
      "Epoch 80training:\n",
      "G_loss: 1.1798970726403324, D_loss_real: 0.5774691730399023, D_loss_fake: 0.5234871182929386\n",
      "Evaluation metrics: {'D_loss': 2.3164394988914845, 'G_acc': 0.6647829201863837, 'D_acc': 0.7124111778995533}\n",
      "Epoch 81training:\n",
      "G_loss: 1.5204821079969406, D_loss_real: 0.4579782723364505, D_loss_fake: 0.39779243977232415\n",
      "Evaluation metrics: {'D_loss': 2.4354941783173714, 'G_acc': 0.7954775419645976, 'D_acc': 0.9529942554021206}\n",
      "Epoch 82training:\n",
      "G_loss: 1.3929389278997075, D_loss_real: 0.5035224985839291, D_loss_fake: 0.4793955840847709\n",
      "Evaluation metrics: {'D_loss': 1.7125349409221986, 'G_acc': 0.5907483105523599, 'D_acc': 1.2893639200709643}\n",
      "Epoch 83training:\n",
      "G_loss: 1.3559080763296647, D_loss_real: 0.5381655023179271, D_loss_fake: 0.47082163285125384\n",
      "Evaluation metrics: {'D_loss': 2.4601026304027576, 'G_acc': 0.7925205940013954, 'D_acc': 0.9580616759898749}\n",
      "Epoch 84training:\n",
      "G_loss: 1.413621560010043, D_loss_real: 0.5199828097766096, D_loss_fake: 0.46825905591249467\n",
      "Evaluation metrics: {'D_loss': 1.9581096524401649, 'G_acc': 0.7021545683627302, 'D_acc': 1.1057415583745185}\n",
      "Epoch 85training:\n",
      "G_loss: 1.6403746984221719, D_loss_real: 0.4207884452305734, D_loss_fake: 0.32402568872679366\n",
      "Evaluation metrics: {'D_loss': 2.06047464961215, 'G_acc': 0.7405619996508168, 'D_acc': 1.0428133970560804}\n",
      "Epoch 86training:\n",
      "G_loss: 1.711729776317423, D_loss_real: 0.4166525026190687, D_loss_fake: 0.2730337828397751\n",
      "Evaluation metrics: {'D_loss': 2.329238655653642, 'G_acc': 0.7998533237633811, 'D_acc': 0.9453060431164627}\n",
      "Epoch 87training:\n",
      "G_loss: 1.8048390041698108, D_loss_real: 0.36944739753803746, D_loss_fake: 0.20751239562576468\n",
      "Evaluation metrics: {'D_loss': 2.4519304840058243, 'G_acc': 0.801969122504719, 'D_acc': 0.9420476648202551}\n",
      "Epoch 88training:\n",
      "G_loss: 1.8207125479524786, D_loss_real: 0.38920199497687546, D_loss_fake: 0.2386177687821063\n",
      "Evaluation metrics: {'D_loss': 2.194168818429344, 'G_acc': 0.758132033687027, 'D_acc': 1.0168141512673137}\n",
      "Epoch 89training:\n",
      "G_loss: 1.5241651830348102, D_loss_real: 0.5387160429223017, D_loss_fake: 0.42947611266916447\n",
      "Evaluation metrics: {'D_loss': 1.7770612313957412, 'G_acc': 0.697229621478313, 'D_acc': 1.1138247938662613}\n",
      "Epoch 90training:\n",
      "G_loss: 1.3262772576375441, D_loss_real: 0.5562440699305047, D_loss_fake: 0.45973092764616014\n",
      "Evaluation metrics: {'D_loss': 2.353182835900104, 'G_acc': 0.7737348293933843, 'D_acc': 0.988537411229598}\n",
      "Epoch 91training:\n",
      "G_loss: 1.5376851379871368, D_loss_real: 0.4833945060487498, D_loss_fake: 0.4399046843702143\n",
      "Evaluation metrics: {'D_loss': 2.0852867624302602, 'G_acc': 0.7613262742796402, 'D_acc': 1.00851897426297}\n",
      "Epoch 92training:\n",
      "G_loss: 1.8013937494971535, D_loss_real: 0.39758725249293175, D_loss_fake: 0.22479936304417522\n",
      "Evaluation metrics: {'D_loss': 2.4444144741858844, 'G_acc': 0.8027223935806936, 'D_acc': 0.9407041120926344}\n",
      "Epoch 93training:\n",
      "G_loss: 1.744095980579203, D_loss_real: 0.39207590058530595, D_loss_fake: 0.2518728254870935\n",
      "Evaluation metrics: {'D_loss': 2.23128266223354, 'G_acc': 0.7819861872266457, 'D_acc': 0.9752261092780168}\n",
      "Epoch 94training:\n",
      "G_loss: 1.6099019066853957, D_loss_real: 0.42265465836972, D_loss_fake: 0.31326670517975636\n",
      "Evaluation metrics: {'D_loss': 2.0777014994250678, 'G_acc': 0.7536476554995682, 'D_acc': 1.0231242472682283}\n",
      "Epoch 95training:\n",
      "G_loss: 1.5530977067622271, D_loss_real: 0.501368443092162, D_loss_fake: 0.3544560592282902\n",
      "Evaluation metrics: {'D_loss': 1.844223911280459, 'G_acc': 0.6406463054949756, 'D_acc': 1.2081920774798318}\n",
      "Epoch 96training:\n",
      "G_loss: 1.321222286061807, D_loss_real: 0.5401586212556471, D_loss_fake: 0.48456637195565483\n",
      "Evaluation metrics: {'D_loss': 1.781655848335108, 'G_acc': 0.6848204983639593, 'D_acc': 1.1260842196836374}\n",
      "Epoch 97training:\n",
      "G_loss: 1.3349775273691524, D_loss_real: 0.5436652573502877, D_loss_fake: 0.5054552640427242\n",
      "Evaluation metrics: {'D_loss': 1.6299311358076303, 'G_acc': 0.5029103076519744, 'D_acc': 1.438026604874764}\n",
      "Epoch 98training:\n",
      "G_loss: 1.0416334222663532, D_loss_real: 0.5846102384342389, D_loss_fake: 0.5870186231353066\n",
      "Evaluation metrics: {'D_loss': 1.900822214820842, 'G_acc': 0.7089194890903068, 'D_acc': 1.0931061585023614}\n",
      "Epoch 99training:\n",
      "G_loss: 0.8539976125413721, D_loss_real: 0.6869646488265557, D_loss_fake: 0.6348717388781634\n",
      "Evaluation metrics: {'D_loss': 1.6878528560999144, 'G_acc': 0.4782861715153709, 'D_acc': 1.46507089357302}\n"
     ]
    }
   ],
   "source": [
    "train(batch_size, seq_length, latent_dim, train_dl, test_dl, discriminator, generator, discriminator_optim, generator_optim, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a3fef",
   "metadata": {},
   "source": [
    "# Anomaly Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b25f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyDetector(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 discriminator: nn.Module,\n",
    "                 generator: nn.Module,\n",
    "                 latent_space_dim: int,\n",
    "                 res_weight: float = .2,\n",
    "                 anomaly_threshold: float = 1.0) -> None:\n",
    "        self.discriminator = discriminator.to('cpu')\n",
    "        self.generator = generator.to('cpu')\n",
    "        self.threshold = anomaly_threshold\n",
    "        self.latent_space_dim = latent_space_dim\n",
    "        self.res_weight = res_weight\n",
    "\n",
    "    def predict(self, tensor: torch.Tensor) -> torch.Tensor:\n",
    "        return (self.predict_proba(tensor) > self.threshold).int()\n",
    "\n",
    "    def predict_proba(self, tensor: torch.Tensor) -> torch.Tensor:\n",
    "        discriminator_score = self.compute_anomaly_score(tensor)\n",
    "        discriminator_score *= 1 - self.res_weight\n",
    "        reconstruction_loss = self.compute_reconstruction_loss(tensor)\n",
    "        reconstruction_loss *= self.res_weight\n",
    "        return discriminator_score #+ reconstruction_loss\n",
    "\n",
    "    def compute_anomaly_score(self, tensor: torch.Tensor) -> torch.Tensor:\n",
    "        with torch.no_grad():\n",
    "            discriminator_score = self.discriminator(tensor)\n",
    "        return discriminator_score\n",
    "\n",
    "    def compute_reconstruction_loss(self,\n",
    "                                    tensor: torch.Tensor) -> torch.Tensor:\n",
    "        best_reconstruct = self._generate_best_reconstruction(tensor)\n",
    "        return (best_reconstruct - tensor).abs().sum(dim=(1, 2))\n",
    "\n",
    "    def _generate_best_reconstruction(self, tensor: torch.Tensor) -> None:\n",
    "        # The goal of this function is to find the corresponding latent space for the given\n",
    "        # input and then generate the best possible reconstruction.\n",
    "        max_iters = 10\n",
    "\n",
    "        Z = torch.empty(\n",
    "            (tensor.size(0), tensor.size(1), self.latent_space_dim),\n",
    "            requires_grad=True)\n",
    "        nn.init.normal_(Z, std=0.05)\n",
    "\n",
    "        optimizer = torch.optim.RMSprop(params=[Z], lr=0.1)\n",
    "        loss_fn = nn.MSELoss(reduction=\"none\")\n",
    "        normalized_target = F.normalize(tensor, dim=1, p=2)\n",
    "\n",
    "        for _ in range(max_iters):\n",
    "            optimizer.zero_grad()\n",
    "            generated_samples = self.generator(Z)\n",
    "            normalized_input = F.normalize(generated_samples, dim=1, p=2)\n",
    "            reconstruction_error = loss_fn(normalized_input,\n",
    "                                           normalized_target).sum(dim=(0, 1, 2))\n",
    "            reconstruction_error.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            best_reconstruct = self.generator(Z)\n",
    "        return best_reconstruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bffd1c3",
   "metadata": {},
   "source": [
    "# EMMV Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f96f3bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def excess_mass(t, t_max, volume_support, s_unif, s_X, n_generated):\n",
    "    EM_t = np.zeros(t.shape[0])\n",
    "    n_samples = s_X.shape[0]\n",
    "    s_X_unique = np.unique(s_X)\n",
    "    EM_t[0] = 1.\n",
    "\n",
    "    for u in s_X_unique:\n",
    "        EM_t = np.maximum(EM_t, 1. / n_samples * (s_X > u).sum() -\n",
    "                        t * (s_unif > u).sum() / n_generated\n",
    "                        * volume_support)\n",
    "    amax = np.argmax(EM_t <= t_max) + 1\n",
    "    if amax == 1:\n",
    "        amax = -1 # failed to achieve t_max\n",
    "    AUC = auc(t[:amax], EM_t[:amax])\n",
    "    return AUC, EM_t, amax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56636fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mass_volume(axis_alpha, volume_support, s_unif, s_X, n_generated):\n",
    "    n_samples = s_X.shape[0]\n",
    "    s_X_argsort = s_X.argsort()\n",
    "    mass = 0\n",
    "    cpt = 0\n",
    "    u = s_X[s_X_argsort[-1]]\n",
    "    mv = np.zeros(axis_alpha.shape[0])\n",
    "    for i in range(axis_alpha.shape[0]):\n",
    "        while mass < axis_alpha[i]:\n",
    "            cpt += 1\n",
    "            u = s_X[s_X_argsort[-cpt]]\n",
    "            mass = 1. / n_samples * cpt  # sum(s_X > u)\n",
    "        mv[i] = float((s_unif >= float(u)).sum()) / n_generated * volume_support\n",
    "    return auc(axis_alpha, mv), mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a93295ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emmv_scores(trained_model, df, scoring_func=None, n_generated=10000, alpha_min=0.9, alpha_max=0.999, t_max=0.9):\n",
    "    \"\"\"Get Excess-Mass (EM) and Mass Volume (MV) scores for unsupervised ML AD models.\n",
    "    :param trained_model: Trained ML model with a 'decision_function' method \n",
    "    :param df: Pandas dataframe of features (X matrix)\n",
    "    :param scoring_func: Anomaly scoring function (callable)\n",
    "    :param n_generated: , defaults to 10000\n",
    "    :param alpha_min: Min value for alpha axis, defaults to 0.9\n",
    "    :param alpha_max: Max value for alpha axis, defaults to 0.999\n",
    "    :param t_max: Min EM value required, defaults to 0.9\n",
    "    :return: A dictionary of two scores ('em' and 'mv')\n",
    "    \"\"\"\n",
    "\n",
    "    if scoring_func is None:\n",
    "        scoring_func = lambda model, df: model.decision_function(df)\n",
    "\n",
    "    # Get limits and volume support.\n",
    "    lim_inf = df.min(axis=0) \n",
    "    lim_sup = df.max(axis=0)\n",
    "    offset = 1e-60 # to prevent division by 0\n",
    "    try:\n",
    "        volume_support = (lim_sup - lim_inf).prod() + offset\n",
    "    except AttributeError as e: # i.e Pandas Series\n",
    "        volume_support = (lim_sup - lim_inf) + offset\n",
    "\n",
    "    # Determine EM and MV parameters\n",
    "    t = np.arange(0, 100 / volume_support, 0.01 / volume_support)\n",
    "    axis_alpha = np.arange(alpha_min, alpha_max, 0.0001)\n",
    "\n",
    "    try:\n",
    "        unif = np.random.uniform(lim_inf, lim_sup, size=(n_generated, df.shape[1]))\n",
    "    except IndexError as e: # i.e. 1D data\n",
    "        unif = np.random.uniform(lim_inf, lim_sup, size=(n_generated))\n",
    "        \n",
    "    # Get anomaly scores\n",
    "    anomaly_score = scoring_func(trained_model, df)#.reshape(1, -1)[0]\n",
    "    s_unif = scoring_func(trained_model, unif)\n",
    "    \n",
    "    # Get EM and MV scores\n",
    "    AUC_em, em, amax = excess_mass(t, t_max, volume_support, s_unif, anomaly_score, n_generated)\n",
    "    AUC_mv, mv = mass_volume(axis_alpha, volume_support, s_unif, anomaly_score, n_generated)\n",
    "    # Return a dataframe containing EMMV information\n",
    "    scores = {\n",
    "        'em': np.mean(em),\n",
    "        'mv': np.mean(mv),\n",
    "    }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e83f62bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_emmv_scores(trained_model, x, scoring_func=None, n_generated=10000, alpha_min=0.9, alpha_max=0.999, t_max=0.9):\n",
    "    \n",
    "    # Get limits and volume support.\n",
    "    lim_inf = torch.min(x.view(-1,6), dim=0)[0]\n",
    "    lim_sup = torch.max(x.view(-1,6), dim=0)[0]\n",
    "    offset = 1e-60 # to prevent division by 0\n",
    "\n",
    "    # Volume support\n",
    "    volume_support = torch.prod(lim_sup - lim_inf).item() + offset\n",
    "\n",
    "    # Determine EM and MV parameters\n",
    "    t = np.arange(0, 100 / volume_support, 0.01 / volume_support)\n",
    "    axis_alpha = np.arange(alpha_min, alpha_max, 0.0001)\n",
    "\n",
    "    unif = torch.rand(n_generated, x.size(1), x.size(2))\n",
    "    m = lim_sup - lim_inf\n",
    "    unif = unif * m\n",
    "    unif = unif + lim_inf\n",
    "\n",
    "    # Get anomaly scores\n",
    "    anomaly_score = scoring_func(trained_model, x).view(-1,1).numpy()\n",
    "    s_unif = scoring_func(trained_model, unif).view(-1,1).numpy()\n",
    "    \n",
    "    # Get EM and MV scores\n",
    "    AUC_em, em, amax = excess_mass(t, t_max, volume_support, s_unif, anomaly_score, n_generated)\n",
    "    AUC_mv, mv = mass_volume(axis_alpha, volume_support, s_unif, anomaly_score, n_generated)\n",
    "\n",
    "    # Return a dataframe containing EMMV information\n",
    "    scores = {\n",
    "        'em': np.mean(em),\n",
    "        'mv': np.mean(mv),\n",
    "    }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b80cc711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_function(model, data):\n",
    "    x = torch.tensor(data, dtype=torch.float32).unsqueeze(dim=0)\n",
    "    out = model.predict(x).squeeze()\n",
    "    return out.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "029f7a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_scoring_function(model, data):\n",
    "    return model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb3eb686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9992)\n",
      "{'em': 0.0001, 'mv': 14253.036804199219}\n",
      "tensor(0.9992)\n",
      "{'em': 0.0001, 'mv': 11815.361022949219}\n",
      "tensor(0.9992)\n",
      "{'em': 0.0001, 'mv': 8953.750305175781}\n",
      "tensor(0.1228)\n",
      "{'em': 0.00010218957500000001, 'mv': 7061.455993652344}\n",
      "tensor(0.5569)\n",
      "{'em': 0.00010404320000000001, 'mv': 1353.2530444702147}\n",
      "tensor(0.9995)\n",
      "{'em': 0.0001, 'mv': 6019.761657714844}\n",
      "tensor(0.9918)\n",
      "{'em': 0.0001, 'mv': 30586.137084960938}\n",
      "tensor(0.9613)\n",
      "{'em': 0.0001, 'mv': 2632.2827911376953}\n",
      "tensor(0.9732)\n",
      "{'em': 0.0001, 'mv': 61709.28955078125}\n",
      "tensor(1.)\n",
      "{'em': 0.0001, 'mv': 1064.2021179199219}\n",
      "tensor(0.9544)\n",
      "{'em': 0.00010443978333333332, 'mv': 30360.598754882812}\n",
      "tensor(0.9997)\n",
      "{'em': 0.0001, 'mv': 1038.9903259277344}\n",
      "tensor(0.9996)\n",
      "{'em': 0.0001, 'mv': 9793.584594726562}\n",
      "tensor(1.)\n",
      "{'em': 0.0001, 'mv': 2186.026840209961}\n",
      "tensor(1.)\n",
      "{'em': 0.0001, 'mv': 1724.6946716308594}\n",
      "tensor(0.6082)\n",
      "{'em': 9.999000099990002e-05, 'mv': 47604.17724609375}\n",
      "tensor(0.7780)\n",
      "{'em': 0.00010079664166666666, 'mv': 129678.6328125}\n",
      "tensor(0.0796)\n",
      "{'em': 0.000109712925, 'mv': 1.2738812769140097e-17}\n",
      "tensor(0.0822)\n",
      "{'em': 0.0001, 'mv': 1.9586491049163044}\n",
      "tensor(0.1445)\n",
      "{'em': 0.00010304985833333333, 'mv': 1428.2810824615476}\n",
      "tensor(0.4398)\n",
      "{'em': 0.0001, 'mv': 115536.5185546875}\n",
      "tensor(0.0039)\n",
      "{'em': 0.00010022636666666667, 'mv': 5.311002505477518e-05}\n",
      "tensor(0.0043)\n",
      "{'em': 0.00010068763750000001, 'mv': 3.2152063224930316e-05}\n",
      "tensor(0.0044)\n",
      "{'em': 0.00010073882500000002, 'mv': 0.005957407993264496}\n",
      "tensor(0.0025)\n",
      "{'em': 0.0001006055, 'mv': 0.007678133260924369}\n",
      "tensor(0.0049)\n",
      "{'em': 0.00010047025000000001, 'mv': 0.00722977303666994}\n",
      "tensor(0.0039)\n",
      "{'em': 0.0001, 'mv': 0.20432918798178434}\n",
      "tensor(0.0036)\n",
      "{'em': 0.00010032885, 'mv': 0.0076977250864729285}\n",
      "tensor(0.0751)\n",
      "{'em': 0.0001, 'mv': 25193.31298828125}\n",
      "tensor(0.9522)\n",
      "{'em': 0.0001, 'mv': 76345.96435546875}\n",
      "tensor(0.9888)\n",
      "{'em': 0.0001, 'mv': 68828.818359375}\n",
      "tensor(1.)\n",
      "{'em': 9.999000099990002e-05, 'mv': 2341.307830810547}\n",
      "tensor(0.9340)\n",
      "{'em': 0.0001, 'mv': 18806.196899414062}\n",
      "tensor(0.9047)\n",
      "{'em': 0.0001, 'mv': 21951.119384765625}\n",
      "tensor(1.)\n",
      "{'em': 0.0001, 'mv': 6829.827117919922}\n",
      "tensor(0.7668)\n",
      "{'em': 0.0001, 'mv': 79151.11083984375}\n",
      "tensor(0.0816)\n",
      "{'em': 0.0001, 'mv': 25.31552429497242}\n",
      "tensor(0.0836)\n",
      "{'em': 0.0001, 'mv': 1.273319365689531}\n",
      "tensor(0.0777)\n",
      "{'em': 0.0001, 'mv': 0.5844231740012766}\n",
      "tensor(0.0789)\n",
      "{'em': 9.999000099990002e-05, 'mv': 0.15061448842529204}\n",
      "tensor(0.5522)\n",
      "{'em': 0.00010139975833333333, 'mv': 1765.9698642517094}\n",
      "tensor(0.9996)\n",
      "{'em': 0.0001, 'mv': 4936.049652099609}\n",
      "tensor(0.2388)\n",
      "{'em': 0.0001, 'mv': 16170.347900390625}\n",
      "tensor(0.0044)\n",
      "{'em': 0.00010056119999999999, 'mv': 0.002411987807136029}\n",
      "tensor(0.0052)\n",
      "{'em': 0.00010045781250000001, 'mv': 0.002325479144928977}\n",
      "tensor(0.0038)\n",
      "{'em': 0.0001, 'mv': 0.29142740182578564}\n",
      "tensor(0.0043)\n",
      "{'em': 0.0001, 'mv': 0.058651878498494625}\n",
      "tensor(0.0052)\n",
      "{'em': 0.00010008790416666666, 'mv': 0.2705819997936487}\n",
      "tensor(0.0039)\n",
      "{'em': 0.0001, 'mv': 0.2981778234243393}\n",
      "tensor(0.0034)\n",
      "{'em': 0.00010010952500000002, 'mv': 0.0007977403206517919}\n",
      "tensor(0.0699)\n",
      "{'em': 9.999000099990002e-05, 'mv': 4548.946838378906}\n",
      "tensor(0.0814)\n",
      "{'em': 0.0001, 'mv': 0.0100673225630424}\n",
      "tensor(0.0816)\n",
      "{'em': 0.00011058351250000001, 'mv': 2.435299999999999e-60}\n",
      "tensor(0.7174)\n",
      "{'em': 0.00010098456250000001, 'mv': 1716.745706542969}\n",
      "tensor(0.8053)\n",
      "{'em': 0.0001, 'mv': 127817.958984375}\n",
      "tensor(0.5905)\n",
      "{'em': 9.999000099990002e-05, 'mv': 144175.2392578125}\n",
      "tensor(0.8109)\n",
      "{'em': 0.0001, 'mv': 44896.651611328125}\n",
      "tensor(0.8706)\n",
      "{'em': 0.000100577575, 'mv': 41584.31396484375}\n",
      "tensor(0.3694)\n",
      "{'em': 0.00010654916666666667, 'mv': 156871.2744140625}\n",
      "tensor(0.0812)\n",
      "{'em': 0.0001, 'mv': 1.8733353943653408}\n",
      "tensor(0.0816)\n",
      "{'em': 0.0001, 'mv': 1.500793917181716}\n",
      "tensor(0.0786)\n",
      "{'em': 0.0001, 'mv': 1.096043084132671}\n",
      "tensor(0.0816)\n",
      "{'em': 0.0001, 'mv': 0.9148710412960496}\n",
      "tensor(0.0819)\n",
      "{'em': 0.0001, 'mv': 0.5287230926550925}\n",
      "tensor(0.0828)\n",
      "{'em': 0.0001, 'mv': 0.4220531244620681}\n",
      "tensor(0.0811)\n",
      "{'em': 0.0001, 'mv': 0.24245859448797993}\n",
      "tensor(0.0796)\n",
      "{'em': 0.0001, 'mv': 0.16365104478932918}\n",
      "tensor(0.0786)\n",
      "{'em': 0.0001108456125, 'mv': 1.2671403412686805e-17}\n",
      "tensor(0.0823)\n",
      "{'em': 0.0001, 'mv': 0.08350310263205321}\n",
      "tensor(0.0809)\n",
      "{'em': 0.000109940325, 'mv': 1.254228856840317e-17}\n",
      "tensor(0.0822)\n",
      "{'em': 0.0001100137125, 'mv': 2.426099999999999e-60}\n",
      "tensor(0.0836)\n",
      "{'em': 0.0001, 'mv': 1.980381906002015}\n",
      "tensor(0.0818)\n",
      "{'em': 0.0001, 'mv': 1.5147129233665768}\n",
      "tensor(0.0796)\n",
      "{'em': 0.0001, 'mv': 0.2740919749708846}\n",
      "tensor(0.0822)\n",
      "{'em': 0.0001, 'mv': 0.011119380075053779}\n",
      "tensor(0.0794)\n",
      "{'em': 0.00010568700833333331, 'mv': 9.775191815642755e-05}\n",
      "tensor(0.0805)\n",
      "{'em': 0.0001091528125, 'mv': 4.4391935013349253e-10}\n",
      "tensor(0.0839)\n",
      "{'em': 0.00010951692330766924, 'mv': 8.265573121779557e-11}\n",
      "tensor(0.0815)\n",
      "{'em': 0.0001103462625, 'mv': 1.4936411065445691e-12}\n",
      "tensor(0.0812)\n",
      "{'em': 0.000109150325, 'mv': 1.4921162360911373e-12}\n",
      "tensor(0.0797)\n",
      "{'em': 0.0001093283, 'mv': 1.4978497489960382e-12}\n",
      "tensor(0.0792)\n",
      "{'em': 0.0001092472375, 'mv': 1.5021193862656443e-12}\n",
      "tensor(0.0784)\n",
      "{'em': 0.000109435475, 'mv': 1.8298445441169986e-11}\n",
      "tensor(0.0799)\n",
      "{'em': 0.00011037765, 'mv': 1.5023633655381932e-12}\n",
      "tensor(0.0823)\n",
      "{'em': 0.00010972798750000001, 'mv': 5.952045265916706e-13}\n",
      "tensor(0.0810)\n",
      "{'em': 0.0001103367875, 'mv': 1.5025463499926053e-12}\n",
      "tensor(0.0801)\n",
      "{'em': 0.0001093733, 'mv': 1.4932751376357452e-12}\n",
      "tensor(0.0797)\n",
      "{'em': 0.0001102549375, 'mv': 1.4949829925435878e-12}\n",
      "tensor(0.0802)\n",
      "{'em': 0.0001098613125, 'mv': 1.4952879666342736e-12}\n",
      "tensor(0.0810)\n",
      "{'em': 0.00010980305, 'mv': 1.988495433180723e-13}\n",
      "tensor(0.0812)\n",
      "{'em': 0.00010926476249999999, 'mv': 1.5082798628975041e-12}\n",
      "tensor(0.0802)\n",
      "{'em': 0.00010957647500000001, 'mv': 1.496446868178881e-12}\n",
      "tensor(0.0818)\n",
      "{'em': 0.0001102328625, 'mv': 1.5051691271725055e-12}\n",
      "tensor(0.0797)\n",
      "{'em': 0.00010947141250000001, 'mv': 1.5031562981739771e-12}\n",
      "tensor(0.0803)\n",
      "{'em': 0.0001098357, 'mv': 1.5098047333509356e-12}\n",
      "tensor(0.0812)\n",
      "{'em': 0.00010909164999999998, 'mv': 1.506023054626427e-12}\n",
      "tensor(0.0819)\n",
      "{'em': 0.00010972840000000002, 'mv': 1.4889445055480016e-12}\n",
      "tensor(0.0814)\n",
      "{'em': 0.0001099363125, 'mv': 1.4876636143671203e-12}\n",
      "tensor(0.0803)\n",
      "{'em': 0.00010916124999999998, 'mv': 1.4989476557225084e-12}\n",
      "tensor(0.0805)\n",
      "{'em': 0.00011041557499999999, 'mv': 1.506450018353388e-12}\n",
      "tensor(0.0803)\n",
      "{'em': 0.0001096065375, 'mv': 1.9886574485335699e-13}\n",
      "tensor(0.0829)\n",
      "{'em': 0.000109734525, 'mv': 5.933662064380164e-13}\n",
      "tensor(0.0859)\n",
      "{'em': 0.000110140875, 'mv': 5.958818024377536e-13}\n",
      "tensor(0.0776)\n",
      "{'em': 0.0001093397, 'mv': 5.935355253995375e-13}\n",
      "tensor(0.0818)\n",
      "{'em': 0.00010889279999999999, 'mv': 1.510353686714171e-12}\n",
      "tensor(0.0775)\n",
      "{'em': 0.0001083595375, 'mv': 1.4970568163602543e-12}\n",
      "tensor(0.0824)\n",
      "{'em': 0.000108993, 'mv': 5.949142655147779e-13}\n",
      "tensor(0.0828)\n",
      "{'em': 0.0001091113875, 'mv': 5.948658886686291e-13}\n",
      "tensor(0.0814)\n",
      "{'em': 0.000109739925, 'mv': 1.4957149303612345e-12}\n",
      "tensor(0.0828)\n",
      "{'em': 0.00010879522499999999, 'mv': 5.934387717072397e-13}\n",
      "tensor(0.0773)\n",
      "{'em': 0.0001092934375, 'mv': 1.988738456209994e-13}\n",
      "tensor(0.0809)\n",
      "{'em': 0.00011011021250000002, 'mv': 1.5017534173568203e-12}\n",
      "tensor(0.0784)\n",
      "{'em': 0.00010962879999999999, 'mv': 1.4990696453587827e-12}\n",
      "tensor(0.0824)\n",
      "{'em': 0.00010978451249999999, 'mv': 1.5030953033558405e-12}\n",
      "tensor(0.0811)\n",
      "{'em': 0.0001097033875, 'mv': 1.503400277446526e-12}\n",
      "tensor(0.0810)\n",
      "{'em': 0.00010927189999999997, 'mv': 1.503583261900938e-12}\n",
      "tensor(0.0816)\n",
      "{'em': 0.0001099275, 'mv': 1.500472526175939e-12}\n",
      "tensor(0.0809)\n",
      "{'em': 0.00011008615, 'mv': 1.5002285469033901e-12}\n",
      "tensor(0.0822)\n",
      "{'em': 0.00010927796250000002, 'mv': 1.5069379768984856e-12}\n",
      "tensor(0.0797)\n",
      "{'em': 0.00011017027499999998, 'mv': 1.4996185987220173e-12}\n",
      "tensor(0.0798)\n",
      "{'em': 0.0001098373125, 'mv': 1.9891434945921143e-13}\n",
      "tensor(0.0811)\n",
      "{'em': 0.000108893625, 'mv': 1.9741570744536681e-13}\n",
      "tensor(0.0783)\n",
      "{'em': 0.00010957347499999999, 'mv': 1.4967518422695671e-12}\n",
      "tensor(0.0818)\n",
      "{'em': 0.0001089142125, 'mv': 1.4962638837244693e-12}\n",
      "tensor(0.0806)\n",
      "{'em': 0.00011037585, 'mv': 1.5025463499926053e-12}\n",
      "tensor(0.0809)\n",
      "{'em': 0.0001088440125, 'mv': 1.503400277446526e-12}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0806)\n",
      "{'em': 0.00010918044999999999, 'mv': 1.496995821542116e-12}\n",
      "tensor(0.0802)\n",
      "{'em': 0.00010980251249999999, 'mv': 1.5012654588117225e-12}\n",
      "tensor(0.0799)\n",
      "{'em': 0.00010904100000000002, 'mv': 1.4952879666342736e-12}\n",
      "tensor(0.0805)\n",
      "{'em': 0.00011001648749999999, 'mv': 1.5033392826283894e-12}\n",
      "tensor(0.0809)\n",
      "{'em': 0.0001090536625, 'mv': 5.940434822840996e-13}\n",
      "tensor(0.0803)\n",
      "{'em': 0.00011073833749999999, 'mv': 1.5093777696239754e-12}\n",
      "tensor(0.0828)\n",
      "{'em': 0.000110238675, 'mv': 5.196860724686251e-14}\n",
      "tensor(0.1051)\n",
      "{'em': 0.00012519291250000003, 'mv': 992.3887781249997}\n",
      "tensor(0.9138)\n",
      "{'em': 0.0001, 'mv': 67595.5517578125}\n",
      "tensor(0.8889)\n",
      "{'em': 0.0001000086625, 'mv': 40409.293212890625}\n",
      "tensor(0.4732)\n",
      "{'em': 0.0001, 'mv': 137376.9140625}\n",
      "tensor(0.0044)\n",
      "{'em': 0.00010026608333333334, 'mv': 0.004676842654589564}\n",
      "tensor(0.0051)\n",
      "{'em': 0.00010061425, 'mv': 0.0052627424884121865}\n",
      "tensor(0.0051)\n",
      "{'em': 0.00010032464999999999, 'mv': 0.006234345637494698}\n",
      "tensor(0.0043)\n",
      "{'em': 0.00010082441755824416, 'mv': 0.0043259967060294}\n",
      "tensor(0.0057)\n",
      "{'em': 9.999000099990002e-05, 'mv': 2.1218571066856384}\n",
      "tensor(0.0036)\n",
      "{'em': 0.000100547775, 'mv': 0.007840849575586617}\n",
      "tensor(0.0043)\n",
      "{'em': 0.0001, 'mv': 3.7323908507823944}\n",
      "tensor(0.0953)\n",
      "{'em': 0.00010235625833333333, 'mv': 122698.82080078125}\n",
      "tensor(0.3221)\n",
      "{'em': 0.00010003623749999999, 'mv': 8970.190754150392}\n",
      "tensor(0.0025)\n",
      "{'em': 0.00010011993749999999, 'mv': 0.009781082044355571}\n",
      "tensor(0.0034)\n",
      "{'em': 0.00010023014166666669, 'mv': 0.006748660525772721}\n",
      "tensor(0.0053)\n",
      "{'em': 0.00010023379583333334, 'mv': 0.2409723959863186}\n",
      "tensor(0.0096)\n",
      "{'em': 0.00010088565833333334, 'mv': 0.0025069096629973505}\n",
      "tensor(0.0033)\n",
      "{'em': 0.00010008305416666667, 'mv': 0.008492281485814601}\n",
      "tensor(0.0053)\n",
      "{'em': 0.00010012534583333332, 'mv': 0.11256253346800804}\n",
      "tensor(0.0038)\n",
      "{'em': 0.0001004569875, 'mv': 0.009970649261958897}\n",
      "tensor(0.0022)\n",
      "{'em': 0.00010017523333333334, 'mv': 0.003711614990606904}\n",
      "tensor(0.0805)\n",
      "{'em': 0.0001, 'mv': 28228.796997070312}\n",
      "tensor(0.1785)\n",
      "{'em': 0.00010327779166666666, 'mv': 7214.9981689453125}\n",
      "tensor(0.1068)\n",
      "{'em': 0.0001, 'mv': 0.7318711654365061}\n",
      "tensor(0.1061)\n",
      "{'em': 0.0001, 'mv': 0.19688157424256209}\n",
      "tensor(0.1102)\n",
      "{'em': 0.0001, 'mv': 0.0631354417696595}\n",
      "tensor(0.1030)\n",
      "{'em': 0.00010177620833333334, 'mv': 0.009717073849809823}\n",
      "tensor(0.1076)\n",
      "{'em': 0.00010766169166666666, 'mv': 0.0004159406144601235}\n",
      "tensor(0.1013)\n",
      "{'em': 0.00011228165933406658, 'mv': 6.7954801405903734e-06}\n",
      "tensor(0.0867)\n",
      "{'em': 0.00010855650833333335, 'mv': 2.6946673459860893e-06}\n",
      "tensor(0.0819)\n",
      "{'em': 0.00010709349166666666, 'mv': 2.680088608803998e-06}\n",
      "tensor(0.0809)\n",
      "{'em': 0.00010739453333333333, 'mv': 2.6916224198657806e-06}\n",
      "tensor(0.0807)\n",
      "{'em': 0.00010773174999999999, 'mv': 2.6680011748112517e-06}\n",
      "tensor(0.0784)\n",
      "{'em': 0.00010871123749999998, 'mv': 5.640469830723304e-08}\n",
      "tensor(0.0831)\n",
      "{'em': 0.00010788169166666668, 'mv': 1.4609116548399469e-06}\n",
      "tensor(0.0801)\n",
      "{'em': 0.00010780236666666667, 'mv': 1.4611166806844268e-06}\n",
      "tensor(0.0798)\n",
      "{'em': 0.00010760741666666667, 'mv': 1.4677287641688963e-06}\n",
      "tensor(0.0828)\n",
      "{'em': 0.00010804538333333334, 'mv': 1.464089555429382e-06}\n",
      "tensor(0.0822)\n",
      "{'em': 0.00010753895, 'mv': 1.4616292452956257e-06}\n",
      "tensor(0.0779)\n",
      "{'em': 0.000108441875, 'mv': 5.6113777304744866e-08}\n",
      "tensor(0.0822)\n",
      "{'em': 0.00010769526666666667, 'mv': 2.264511707596739e-06}\n",
      "tensor(0.0827)\n",
      "{'em': 0.000106931175, 'mv': 2.253213863093606e-06}\n",
      "tensor(0.3611)\n",
      "{'em': 0.00011192887499999999, 'mv': 809.5548673767094}\n",
      "tensor(0.9622)\n",
      "{'em': 0.0001, 'mv': 124124.1064453125}\n",
      "tensor(0.9952)\n",
      "{'em': 0.00010130481249999998, 'mv': 39984.9755859375}\n",
      "tensor(0.9187)\n",
      "{'em': 0.0001, 'mv': 76531.91162109375}\n",
      "tensor(0.6224)\n",
      "{'em': 0.0001, 'mv': 118836.01318359375}\n",
      "tensor(0.)\n",
      "{'em': 0.0001, 'mv': 0.009943592303898185}\n",
      "tensor(0.)\n",
      "{'em': 0.0001, 'mv': 1.096516102552414}\n",
      "tensor(0.)\n",
      "{'em': 0.0001, 'mv': 0.007296963594853878}\n",
      "tensor(0.)\n",
      "{'em': 0.0001, 'mv': 0.008925680886022747}\n",
      "tensor(0.)\n",
      "{'em': 0.0001, 'mv': 0.09280372643843293}\n",
      "tensor(0.)\n",
      "{'em': 0.0001, 'mv': 0.0033368985168635845}\n",
      "tensor(0.)\n",
      "{'em': 0.0001, 'mv': 0.006111198017606512}\n",
      "tensor(0.3227)\n",
      "{'em': 0.0001, 'mv': 11312.379455566406}\n",
      "tensor(0.9957)\n",
      "{'em': 0.00010156225, 'mv': 20164.092407226562}\n",
      "tensor(0.7260)\n",
      "{'em': 0.0001, 'mv': 51827.4609375}\n",
      "tensor(0.3596)\n",
      "{'em': 0.00010241926224044263, 'mv': 19907.68798828125}\n",
      "tensor(0.2815)\n",
      "{'em': 0.000111259, 'mv': 1522.8093278320314}\n",
      "tensor(0.9648)\n",
      "{'em': 0.0001, 'mv': 7665.6884765625}\n",
      "0.00010424619541074167 11476.447596684891\n"
     ]
    }
   ],
   "source": [
    "ad = AnomalyDetector(discriminator=discriminator, generator=generator, latent_space_dim=latent_dim, anomaly_threshold=0.5)\n",
    "total_em = total_mv = 0\n",
    "for X, Y in test_dl:\n",
    "    prediction = ad.predict(X)\n",
    "    acc = (prediction == Y).float()\n",
    "    acc = acc.sum().div(batch_size)/30\n",
    "    print(acc)\n",
    "    scores = torch_emmv_scores(ad,X,torch_scoring_function)\n",
    "    print(scores)\n",
    "    total_em += scores['em']\n",
    "    total_mv += scores['mv']\n",
    "print(total_em/len(test_dl),total_mv/len(test_dl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
